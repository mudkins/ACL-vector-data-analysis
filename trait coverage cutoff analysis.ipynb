{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "585ae129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, log_loss\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "from matplotlib.pyplot import figure\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from nested_cv import NestedCV\n",
    "from IPython.display import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import pickle\n",
    "\n",
    "#ignore warnings if you want\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c12f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make function to match the status for what ever parasite it is, binarize it, and drop unnecessary columns\n",
    "def gettrain(df, parasite):\n",
    "    #matching the sandfly status for the species of parasite to the sandfly in the larger dataframe\n",
    "    for j in range(len(df)):\n",
    "        for i in range(len(status)):\n",
    "            if df.loc[j, 'species'] == status.loc[i, 'species']:\n",
    "                df.loc[j, parasite] = status.loc[i, parasite]\n",
    "    #fill the remaining vector status column with 0s, then binarize the status\n",
    "    df[parasite] = df[parasite].fillna(0).map(lambda x : x//2)\n",
    "    #set the index as the species name\n",
    "    train = df.set_index('species')\n",
    "    #drop unnecessary columns\n",
    "    train = train.drop(columns=['Unnamed: 0', '.imp', '.id'])\n",
    "    if 'index' in df.columns:\n",
    "        train = train.drop(columns=['index'])\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e1616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstatus(df, parasite):\n",
    "    for i in range(len(status)):\n",
    "        for j in range(len(df)):\n",
    "            if status.loc[i, 'species'] == df.loc[j, 'species']:\n",
    "                df.loc[j, 'potential/proven'] = status.loc[i, parasite]\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('raw data/vector trait data final.csv')\n",
    "original = original.drop(columns=['Argentina', 'Belize','Bolivia', 'Brazil', 'Canada', 'CaymanIslands', 'Chile', 'Colombia', 'Costa.Rica', 'Cuba', 'Dominican.Republic', 'Ecuador', 'El.Salvador', 'French.Guiana','Guadeloupe', 'Guatemala', 'Grenada', 'Guyana', 'Haiti', 'Honduras', 'Jamaica','Martinica', 'Mexico', 'Nicaragua', 'Panama', 'Paraguay','PuertoRico', 'Peru', 'Suriname', 'TrinidadTobago', 'Uruguay', 'USA', 'Venezuela','VirginIslands'])\n",
    "status = pd.read_csv('raw data/sandfly status.csv')\n",
    "#if sandfly is a proven vector for any species of leish, mark it in a new column 'cl' as 1\n",
    "status['leish'] = 0\n",
    "for i in range(len(status)):\n",
    "    if 2 in status.values.tolist()[i]:\n",
    "        status.loc[i, 'leish'] = 2\n",
    "    elif 1 in status.values.tolist()[i]:\n",
    "        status.loc[i, 'leish'] = 1\n",
    "\n",
    "#get cleaned train datasets in a list\n",
    "parasite = 'leish'\n",
    "for j in range(len(original)):\n",
    "    for i in range(len(status)):\n",
    "        if original.loc[j, 'species'] == status.loc[i, 'species']:\n",
    "            original.loc[j, parasite] = status.loc[i, parasite]\n",
    "\n",
    "#fill the remaining vector status column with 0s, then binarize the status\n",
    "original[parasite] = original[parasite].fillna(0).map(lambda x : x//2)\n",
    "#set the index as the species name\n",
    "original = original.set_index('species')\n",
    "#drop unnecessary columns\n",
    "original_clean = original.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "####LOOK AT CORRELLATED VARIABLES\n",
    "#tribe_Hertigiini is corr w 'genus_Warileya'\n",
    "#subtribe_hertigiina is corr w 'genus_Warileya'\n",
    "#peri is corr w semi.domestic\n",
    "#'genus_Brumptomyia' is corr w 'subtribe_Brumptomyiina'\n",
    "#'genus_Micropygomyia' is corr w 'subtribe_Sergentomyiina'\n",
    "\n",
    "#wing_width / hs.canopy\n",
    "#wing_width / hs.floor\n",
    "#labruml_wingl / log.labrum.length\n",
    "#log.grass.cover / log.shrub.cover\n",
    "#domestic / intra\n",
    "#wing.width/temp \n",
    "#log.elevation / temp\n",
    "#log.temp.var / temp.range\n",
    "#maxshape_sabre / genus_Brumptomyia\n",
    "#log.dental.depth / log.labrum.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50061ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = original.isna().sum()\n",
    "cov_df = pd.DataFrame(coverage)\n",
    "cov_df[0] = (512 - cov_df[0])/512\n",
    "cov_df.to_csv(\"no bites man/primary model/trait coverage.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff48a47",
   "metadata": {},
   "source": [
    "## no cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de41160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('raw data/all trait data and encoded.csv')\n",
    "original = original.drop(columns=['Argentina', 'Belize','Bolivia', 'Brazil', 'Canada', 'CaymanIslands', 'Chile', 'Colombia', 'Costa Rica', 'Cuba', 'Dominican Republic', 'Ecuador', 'El Salvador', 'French Guiana','Guadeloupe', 'Guatemala', 'Grenada', 'Guyana', 'Haiti', 'Honduras', 'Jamaica','Martinica', 'Mexico', 'Nicaragua', 'Panama', 'Paraguay','PuertoRico', 'Peru', 'Suriname', 'TrinidadTobago', 'Uruguay', 'USA', 'Venezuela','VirginIslands'])\n",
    "status = pd.read_csv('raw data/sandfly status.csv')\n",
    "#if sandfly is a proven vector for any species of leish, mark it in a new column 'cl' as 1\n",
    "status['leish'] = 0\n",
    "for i in range(len(status)):\n",
    "    if 2 in status.values.tolist()[i]:\n",
    "        status.loc[i, 'leish'] = 2\n",
    "    elif 1 in status.values.tolist()[i]:\n",
    "        status.loc[i, 'leish'] = 1\n",
    "\n",
    "#get cleaned train datasets in a list\n",
    "parasite = 'leish'\n",
    "for j in range(len(original)):\n",
    "    for i in range(len(status)):\n",
    "        if original.loc[j, 'species'] == status.loc[i, 'species']:\n",
    "            original.loc[j, parasite] = status.loc[i, parasite]\n",
    "\n",
    "#fill the remaining vector status column with 0s, then binarize the status\n",
    "original[parasite] = original[parasite].fillna(0).map(lambda x : x//2)\n",
    "#set the index as the species name\n",
    "original = original.set_index('species', drop=True)\n",
    "#drop unnecessary columns\n",
    "original = original.drop(columns=['Unnamed: 0', 'bites.man', 'order.notes'])\n",
    "\n",
    "####LOOK AT CORRELLATED VARIABLES\n",
    "#tribe_Hertigiini is corr w 'genus_Warileya'\n",
    "#subtribe_hertigiina is corr w 'genus_Warileya'\n",
    "#peri is corr w semi.domestic\n",
    "#'genus_Brumptomyia' is corr w 'subtribe_Brumptomyiina'\n",
    "#'genus_Micropygomyia' is corr w 'subtribe_Sergentomyiina'\n",
    "\n",
    "#wing_width / hs.canopy\n",
    "#wing_width / hs.floor\n",
    "#labruml_wingl / log.labrum.length\n",
    "#log.grass.cover / log.shrub.cover\n",
    "#domestic / intra\n",
    "#wing.width/temp \n",
    "#log.elevation / temp\n",
    "#log.temp.var / temp.range\n",
    "#maxshape_sabre / genus_Brumptomyia\n",
    "#log.dental.depth / log.labrum.length\n",
    "\n",
    "original_clean = original.drop(columns=['subtribe_Sergentomyiina', 'subtribe_Brumptomyiina',\n",
    "                                              'peri', 'subtribe_Hertigiina', 'tribe_Hertigiini',\n",
    "                                              'wing.width', 'labruml_wingl', 'shrub.cover',\n",
    "                                              'intra', 'elevation', 'temp.var', 'maxshape_sabre', 'dental.depth'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba54336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# think i have to redo the one hot encoding\n",
    "# tribe, subtribe, genus, max.shape, hypo.teeth\n",
    "no_cutoff = original_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f9ef977",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From the hyperopt docs\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe\n",
    "'''\n",
    "## For the argument named 'a', choose either of the two tuples, each of which has a second\n",
    "## argument drawn from a given distribution and given a name ('c1'/'c2')\n",
    "space = hp.choice('a',\n",
    "    [\n",
    "        ('case 1', 1 + hp.lognormal('c1', 0, 1)),\n",
    "        ('case 2', hp.uniform('c2', -10, 10))\n",
    "    ])\n",
    "\n",
    "# minimize the objective over the space\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "'''\n",
    "###TRY TO GET THE AUC, CHANGE THE THRESHHOLD PROBABILITY\n",
    "\n",
    "def val_test(best, train_x, train_y, val_x, val_y, graph=False):\n",
    "    params = {'max_depth': int(best['max_depth']), 'gamma': best['gamma'],\n",
    "                  'learning_rate': best['learning_rate'], 'n_estimators': int(best['n_estimators']),\n",
    "                  'scale_pos_weight': int(best['scale_pos_weight']), 'colsample_bytree': best['colsample_bytree']}\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric = 'logloss', objective = 'binary:logistic', **params)\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    \n",
    "\n",
    "    #use the mean of the probabilities as the threshold for a positive prediction\n",
    "    prob = np.array(pd.DataFrame(model.predict_proba(val_x))[1])\n",
    "    for x in range(len(prob)):\n",
    "        if prob[x] > np.mean(np.array(pd.DataFrame(model.predict_proba(val_x))[1])):\n",
    "            prob[x] = 1\n",
    "        else:\n",
    "            prob[x] = 0\n",
    "        \n",
    "    y_preds = prob\n",
    "    \n",
    "               \n",
    "#         plot_roc_curve(model, val_x, val_y)\n",
    "#         plt.ylabel('True Positive Rate')\n",
    "#         plt.xlabel('False Positive Rate')\n",
    "#         plt.show()\n",
    "               \n",
    "    return roc_auc_score(val_y, y_preds)\n",
    "\n",
    "primary_parameters = []\n",
    "def do_nested_cv(data):\n",
    "    '''\n",
    "    - Split data into train, test\n",
    "    - Split train into k (stratified) folds\n",
    "    '''\n",
    "    \n",
    "    # Begin code here\n",
    "    X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=3)\n",
    "    folds = cv.split(X_train, y_train)\n",
    "    \n",
    "\n",
    "    \n",
    "    # End code here\n",
    "    models_with_scores = []\n",
    "    for (train, val) in folds:\n",
    "        '''\n",
    "        - Split x into n more (stratified) folds\n",
    "        - Now, use Bayesian optimization to minimize objective function\n",
    "        - After Bayesian optimization, evaluate the model on val and store the model\n",
    "        '''\n",
    "        # Begin code here\n",
    "        train_x, train_y = X_train.iloc[train], y_train.iloc[train]\n",
    "        val_x, val_y = X_train.iloc[val], y_train.iloc[val]\n",
    "        inner_cv = StratifiedKFold(n_splits=3)\n",
    "        \n",
    "        inner_folds = inner_cv.split(train_x, train_y)\n",
    "        inner_folds = [(train,test) for train, test in inner_folds]\n",
    "        \n",
    "        def objective_function(params):\n",
    "            '''\n",
    "            Given a set of n (inner) folds, train n models and return the average validation loss over all folds.\n",
    "            '''\n",
    "            scores = []\n",
    "            params = {'max_depth': int(params[0]), 'gamma': params[1],\n",
    "                      'learning_rate': params[2], 'n_estimators': int(params[3]),\n",
    "                      'scale_pos_weight': int(params[4]), 'colsample_bytree': params[5]}\n",
    "\n",
    "            for (itrain, ival) in inner_folds:\n",
    "                # Begin code here\n",
    "                '''\n",
    "                - Train a model on n\n",
    "                - Evaluate on val\n",
    "                - Store the score to return the average over all folds\n",
    "                '''\n",
    "                inner_train_x, inner_train_y = train_x.iloc[itrain], train_y.iloc[itrain]\n",
    "                inner_val_x, inner_val_y = train_x.iloc[ival], train_y.iloc[ival]\n",
    "                \n",
    "                \n",
    "\n",
    "                model = XGBClassifier(use_label_encoder=False, eval_metric = 'logloss', **params, objective='binary:logistic')\n",
    "                model.fit(inner_train_x, inner_train_y)\n",
    "            \n",
    "                y_preds = model.predict(inner_val_x)\n",
    "                scores.append(1-roc_auc_score(inner_val_y, y_preds))\n",
    "\n",
    "            return np.mean(scores)\n",
    "                # End code here\n",
    "            \n",
    "        \n",
    "        #bayes\n",
    "\n",
    "        space = hp.choice('a', [(hp.uniform('max_depth', 0, 10),\n",
    "                                 hp.uniform('gamma', 10, 1000), \n",
    "                                 hp.uniform('learning_rate', 0, 1), \n",
    "                                 hp.uniform('n_estimators', 100, 200),\n",
    "                                 hp.uniform('scale_pos_weight', 0, 15),\n",
    "                                 hp.uniform('colsample_bytree', 0.2, 1)\n",
    "                                )])\n",
    "        \n",
    "\n",
    "            \n",
    "        best = fmin(objective_function, space, algo=tpe.suggest, max_evals=100)\n",
    "        models_with_scores.append((best, val_test(best, train_x, train_y, val_x, val_y)))\n",
    "        \n",
    "        primary_parameters.append((best, val_test(best, train_x, train_y, val_x, val_y)))\n",
    "\n",
    "        # End code here\n",
    "        \n",
    "\n",
    "    \n",
    "    '''\n",
    "    - Now, there are k models. Pick the best one, or create an ensemble model\n",
    "    '''\n",
    "    # Begin code here\n",
    "    models_with_scores = sorted(models_with_scores, key = lambda x: x[1])\n",
    "    best_params_overall = models_with_scores[-1][0]\n",
    "    \n",
    "    final_test_score = val_test(best_params_overall, X_train, y_train, X_test, y_test, True)\n",
    "    print(\"Final Test Score is \" + str(final_test_score))\n",
    "    print('best = ' + str(best_params_overall))\n",
    "    # End code here\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "109ad3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['act.di', 'act.noct', 'act.crep', 'hs.canopy', 'hs.floor', 'b.tsmbf',\n",
       "       'b.tsdbf', 'b.tsgss', 'b.mangrove', 'b.fgs', 'b.dxs', 'b.tscf',\n",
       "       'b.tgss', 'b.tcforest', 'b.tbmforest', 'b.montane', 'mh.flfs', 'mh.ab',\n",
       "       'mh.bwa', 'mh.tttr', 'mh.th', 'mh.tt', 'mh.cr', 'mh.ca', 'mh.fwsl',\n",
       "       'mh.ma', 'mh.ada', 'mh.oihd', 'exta', 'wild', 'semi.domestic',\n",
       "       'domestic', 'bites.mammals', 'seas.wint', 'seas.summ', 'lifespan',\n",
       "       'gonotrophic', 'cl.size', 'citations', 'labrum.length',\n",
       "       'Labrumepipharynx.length', 'A3_wingl', 'no.lat.teeth', 'no.ven.teeth',\n",
       "       'no.cib.teeth', 'wing.length', 'wingl_wingw', 'A3', 'temp',\n",
       "       'temp.range', 'rainfall', 'flii', 'wind.speed', 'canopy', 'ghm',\n",
       "       'tree.cover', 'crops.cover', 'grass.cover', 'urban.cover',\n",
       "       'water.perm.cover', 'water.seas.cover', 'evi', 'ecoregion.breadth',\n",
       "       'synarthropy', 'tribe_Phlebotomini', 'subtribe_Lutzomyiina',\n",
       "       'subtribe_Psychodopygina', 'genus_Bichromomyia', 'genus_Brumptomyia',\n",
       "       'genus_Dampfomyia', 'genus_Deanemyia', 'genus_Evandromyia',\n",
       "       'genus_Expapillata', 'genus_Hertigia', 'genus_Lutzomyia',\n",
       "       'genus_Martinsmyia', 'genus_Micropygomyia', 'genus_Migonemyia',\n",
       "       'genus_Nyssomyia', 'genus_Oligodontomyia', 'genus_Pintomyia',\n",
       "       'genus_Pressatia', 'genus_Psathyromyia', 'genus_Psychodopygus',\n",
       "       'genus_Sciopemyia', 'genus_Trichophoromyia', 'genus_Trichopygomyia',\n",
       "       'genus_Viannamyia', 'genus_Warileya', 'maxshape_spear',\n",
       "       'hypoteeth_rough', 'hypoteeth_smooth', 'hypoteeth_spiculate', 'leish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_cutoff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8cf1d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:42<00:00,  1.02s/trial, best loss: 0.23412698412698407]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16trial/s, best loss: 0.22999533146591966]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.24773576097105507]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.3651433380024935, 'gamma': 27.53387820485778, 'learning_rate': 0.4525665263739257, 'max_depth': 5.435992713245172, 'n_estimators': 190.72384358368748, 'scale_pos_weight': 14.997968752622484}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:36<00:00,  1.04trial/s, best loss: 0.18253968253968259]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:43<00:00,  1.04s/trial, best loss: 0.23190943043884218]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:41<00:00,  1.01s/trial, best loss: 0.2796685340802989]\n",
      "Final Test Score is 0.8177083333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.5397328684098243, 'gamma': 12.163433226594165, 'learning_rate': 0.08635890156631659, 'max_depth': 8.878898829648481, 'n_estimators': 164.0798567839276, 'scale_pos_weight': 14.338232957408694}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.2539682539682539]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.24369747899159663]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:28<00:00,  1.13trial/s, best loss: 0.22394957983193275]\n",
      "Final Test Score is 0.7827380952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.7607184668599923, 'gamma': 15.338421960626302, 'learning_rate': 0.2831736207236424, 'max_depth': 7.4562333041948134, 'n_estimators': 198.99504090993852, 'scale_pos_weight': 10.792719541343299}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.15476190476190477]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:29<00:00,  1.12trial/s, best loss: 0.19631185807656393]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.41trial/s, best loss: 0.19808590102707746]\n",
      "Final Test Score is 0.7723214285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.2019259145577685, 'gamma': 15.687661785484451, 'learning_rate': 0.06490290968651374, 'max_depth': 9.187300438840047, 'n_estimators': 199.0225573275696, 'scale_pos_weight': 12.276427096893869}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:06<00:00,  1.51trial/s, best loss: 0.19444444444444442]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.22584033613445378]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.2081232492997199]\n",
      "Final Test Score is 0.7477678571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.538907111454439, 'gamma': 10.055252092239698, 'learning_rate': 0.24858924923163517, 'max_depth': 2.3077935252156347, 'n_estimators': 148.77225453031056, 'scale_pos_weight': 10.223226381728942}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.23015873015873012]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.19808590102707746]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.20189075630252096]\n",
      "Final Test Score is 0.7410714285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.630265308996841, 'gamma': 71.91090325860901, 'learning_rate': 0.29556673712304404, 'max_depth': 6.299180260927006, 'n_estimators': 110.76293528261104, 'scale_pos_weight': 14.993932098896723}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.49trial/s, best loss: 0.22817460317460314]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.37trial/s, best loss: 0.12275910364145659]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.2894257703081233]\n",
      "Final Test Score is 0.8400297619047619\n",
      "best = {'a': 0, 'colsample_bytree': 0.40164753187665797, 'gamma': 28.559520054699476, 'learning_rate': 0.8374069745316288, 'max_depth': 3.01785117885224, 'n_estimators': 105.96021058675966, 'scale_pos_weight': 12.971274443091584}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.17063492063492058]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.1645191409897292]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.11879084967320257]\n",
      "Final Test Score is 0.6346726190476191\n",
      "best = {'a': 0, 'colsample_bytree': 0.6127921034112235, 'gamma': 59.71570231907379, 'learning_rate': 0.7972877539886658, 'max_depth': 3.973943294628785, 'n_estimators': 128.76415161544995, 'scale_pos_weight': 11.758892451276242}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.28trial/s, best loss: 0.13888888888888887]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.18214285714285708]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.24591503267973858]\n",
      "Final Test Score is 0.7008928571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.7071808591885024, 'gamma': 20.067369362076136, 'learning_rate': 0.4390826546348168, 'max_depth': 6.4602183058218525, 'n_estimators': 158.78514763587282, 'scale_pos_weight': 10.888957822689871}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.18055555555555555]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:06<00:00,  1.50trial/s, best loss: 0.24586834733893556]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.23382352941176468]\n",
      "Final Test Score is 0.7619047619047621\n",
      "best = {'a': 0, 'colsample_bytree': 0.5422306890803901, 'gamma': 11.26829538542206, 'learning_rate': 0.10011892906680442, 'max_depth': 3.0718657821617006, 'n_estimators': 129.45889562562695, 'scale_pos_weight': 14.170334548198243}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:05<00:00,  1.52trial/s, best loss: 0.20039682539682535]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.19024276377217555]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:28<00:00,  1.13trial/s, best loss: 0.23576097105508867]\n",
      "Final Test Score is 0.8177083333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.29695342375826017, 'gamma': 63.45985679706192, 'learning_rate': 0.6308170272445153, 'max_depth': 8.74929420802718, 'n_estimators': 192.135966165218, 'scale_pos_weight': 8.812480547785666}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.23611111111111113]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.21008403361344538]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.2062091503267974]\n",
      "Final Test Score is 0.8697916666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.4742665764155532, 'gamma': 33.01632495157665, 'learning_rate': 0.38452367221557604, 'max_depth': 9.980998893682866, 'n_estimators': 126.69402392330403, 'scale_pos_weight': 9.063264090113076}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.21428571428571427]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.24379084967320255]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:19<00:00,  1.25trial/s, best loss: 0.1799953314659197]\n",
      "Final Test Score is 0.828125\n",
      "best = {'a': 0, 'colsample_bytree': 0.6045464220438499, 'gamma': 50.30162964915718, 'learning_rate': 0.7628779121496082, 'max_depth': 3.2598930467037626, 'n_estimators': 153.3301090378804, 'scale_pos_weight': 6.480618268891967}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.26984126984126977]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.3053221288515406]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:04<00:00,  1.55trial/s, best loss: 0.21388888888888893]\n",
      "Final Test Score is 0.8333333333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.41864589532804275, 'gamma': 99.20289217649801, 'learning_rate': 0.44377864010951357, 'max_depth': 3.8715848628969773, 'n_estimators': 148.18476166031215, 'scale_pos_weight': 11.426528436694941}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.1944444444444444]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.21022408963585437]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:05<00:00,  1.53trial/s, best loss: 0.2715452847805789]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.4365640482281041, 'gamma': 21.35984309101849, 'learning_rate': 0.32144741245915287, 'max_depth': 2.743855173312063, 'n_estimators': 128.2908130038173, 'scale_pos_weight': 14.881232473498468}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.37trial/s, best loss: 0.2341269841269841]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.26946778711484587]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:30<00:00,  1.11trial/s, best loss: 0.26372549019607844]\n",
      "Final Test Score is 0.8072916666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.9992427080925967, 'gamma': 31.20862361054456, 'learning_rate': 0.7825411255355536, 'max_depth': 5.481711241451069, 'n_estimators': 193.14698640396725, 'scale_pos_weight': 11.288316961799984}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.21825396825396826]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.2871381886087768]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.28517740429505134]\n",
      "Final Test Score is 0.8072916666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.6329041318514497, 'gamma': 86.93195019163798, 'learning_rate': 0.39719098622085836, 'max_depth': 8.128931870854348, 'n_estimators': 152.55559910386046, 'scale_pos_weight': 13.882125057245563}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.16865079365079363]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.26918767507002794]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.19619514472455646]\n",
      "Final Test Score is 0.84375\n",
      "best = {'a': 0, 'colsample_bytree': 0.6837503535049951, 'gamma': 45.25283878829119, 'learning_rate': 0.1747599214684141, 'max_depth': 5.78149119545527, 'n_estimators': 148.8515495221367, 'scale_pos_weight': 12.536362502148506}\n",
      "100%|██████████████████████████████████████████████| 100/100 [07:30<00:00,  4.50s/trial, best loss: 0.2043650793650793]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:34<00:00,  1.06trial/s, best loss: 0.22560690943043885]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.2318160597572362]\n",
      "Final Test Score is 0.746279761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.6788024130899005, 'gamma': 73.72082640322373, 'learning_rate': 0.6513639893997507, 'max_depth': 9.934845515262683, 'n_estimators': 199.57186446276896, 'scale_pos_weight': 14.873398481468383}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.20238095238095236]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:10<00:00,  1.41trial/s, best loss: 0.2141456582633053]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.11879084967320253]\n",
      "Final Test Score is 0.7165178571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.9707024425692455, 'gamma': 10.685081183217278, 'learning_rate': 0.27476053749257767, 'max_depth': 5.262851476547577, 'n_estimators': 130.93896462560636, 'scale_pos_weight': 11.93859433876092}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.25992063492063494]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.22399626517273577]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.25971055088702144]\n",
      "Final Test Score is 0.90625\n",
      "best = {'a': 0, 'colsample_bytree': 0.30016479128044654, 'gamma': 14.157551965009006, 'learning_rate': 0.4737542869054675, 'max_depth': 7.686733941881964, 'n_estimators': 192.48827056385375, 'scale_pos_weight': 6.267876988641419}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19trial/s, best loss: 0.25992063492063494]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.21816059757236228]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:09<00:00,  1.45trial/s, best loss: 0.2201213818860878]\n",
      "Final Test Score is 0.746279761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.37095199170732435, 'gamma': 32.02366878785539, 'learning_rate': 0.02838796848994396, 'max_depth': 2.3122566328231415, 'n_estimators': 118.61525410830954, 'scale_pos_weight': 7.43679108571778}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.19047619047619047]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.25982726423902897]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.15849673202614376]\n",
      "Final Test Score is 0.828125\n",
      "best = {'a': 0, 'colsample_bytree': 0.5155785093436592, 'gamma': 92.78385525439077, 'learning_rate': 0.5156916632507211, 'max_depth': 6.616634862443, 'n_estimators': 101.06428336176876, 'scale_pos_weight': 13.980770980293793}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.2619047619047619]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2280812324929973]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.22997198879551817]\n",
      "Final Test Score is 0.8541666666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.40597030758335473, 'gamma': 16.867559648936023, 'learning_rate': 0.3777675491721336, 'max_depth': 3.69986272941291, 'n_estimators': 177.19872442254604, 'scale_pos_weight': 9.12999444832615}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.43trial/s, best loss: 0.13690476190476186]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.2477124183006536]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.2654761904761905]\n",
      "Final Test Score is 0.6800595238095238\n",
      "best = {'a': 0, 'colsample_bytree': 0.5648881466858459, 'gamma': 107.72112694082925, 'learning_rate': 0.5875529623510319, 'max_depth': 7.871404767150553, 'n_estimators': 191.32195236155712, 'scale_pos_weight': 11.31425717418345}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.20039682539682535]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.19038281979458446]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.18629785247432304]\n",
      "Final Test Score is 0.6629464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.25526800243254166, 'gamma': 103.96997591588519, 'learning_rate': 0.721421965513203, 'max_depth': 5.9545860740166345, 'n_estimators': 152.29849446762483, 'scale_pos_weight': 14.180435568192856}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:05<00:00,  1.52trial/s, best loss: 0.24999999999999997]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.18041549953314653]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:08<00:00,  1.47trial/s, best loss: 0.2356909430438842]\n",
      "Final Test Score is 0.8177083333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.40010793163991915, 'gamma': 22.88492739097786, 'learning_rate': 0.14952035191102792, 'max_depth': 1.5189308630488947, 'n_estimators': 170.07891013878753, 'scale_pos_weight': 13.208108729594253}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.1527777777777777]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.21594304388422025]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.24943977591036412]\n",
      "Final Test Score is 0.7254464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.7728070715543122, 'gamma': 90.24197728305894, 'learning_rate': 0.2510785703533928, 'max_depth': 5.359953267661735, 'n_estimators': 135.12130862380454, 'scale_pos_weight': 13.589372913935174}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.2837301587301588]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.1048319327731092]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.13062558356676002]\n",
      "Final Test Score is 0.828125\n",
      "best = {'a': 0, 'colsample_bytree': 0.85613393285499, 'gamma': 37.06076740806591, 'learning_rate': 0.8252906293736391, 'max_depth': 6.664368076122538, 'n_estimators': 160.07367376553532, 'scale_pos_weight': 6.480190582926123}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.24007936507936498]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.23783846872082168]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.22173202614379084]\n",
      "Final Test Score is 0.828125\n",
      "best = {'a': 0, 'colsample_bytree': 0.2774614950453149, 'gamma': 80.62060897232317, 'learning_rate': 0.6972177010175381, 'max_depth': 7.231012722009117, 'n_estimators': 127.12844326785262, 'scale_pos_weight': 13.37881001207353}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.28trial/s, best loss: 0.17658730158730154]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.17833800186741355]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.23786181139122317]\n",
      "Final Test Score is 0.7671130952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.3264879448662473, 'gamma': 24.655154578075475, 'learning_rate': 0.07062608519982763, 'max_depth': 6.5298867680793, 'n_estimators': 141.76782826953098, 'scale_pos_weight': 14.21194946075817}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.15079365079365073]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.16trial/s, best loss: 0.16449579831932773]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.18991596638655453]\n",
      "Final Test Score is 0.6904761904761906\n",
      "best = {'a': 0, 'colsample_bytree': 0.7022882936343338, 'gamma': 110.34058585530781, 'learning_rate': 0.4511753645205214, 'max_depth': 4.275690613863636, 'n_estimators': 142.13971668364167, 'scale_pos_weight': 9.664870323332213}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.19246031746031747]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.2059757236227825]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2276844070961718]\n",
      "Final Test Score is 0.6138392857142857\n",
      "best = {'a': 0, 'colsample_bytree': 0.6277065343414368, 'gamma': 67.4242176580071, 'learning_rate': 0.4921982985521146, 'max_depth': 8.02934390891713, 'n_estimators': 154.29501074769962, 'scale_pos_weight': 13.951634340243137}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.2936507936507936]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.20023342670401498]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.2318860877684407]\n",
      "Final Test Score is 0.84375\n",
      "best = {'a': 0, 'colsample_bytree': 0.6179259795032874, 'gamma': 13.632485083831174, 'learning_rate': 0.10964179478201341, 'max_depth': 4.628008199331653, 'n_estimators': 115.56868691695591, 'scale_pos_weight': 14.980831752320046}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.16468253968253968]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.17840802987861806]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.28trial/s, best loss: 0.23788515406162467]\n",
      "Final Test Score is 0.8191964285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.8021840041590362, 'gamma': 13.771658849476067, 'learning_rate': 0.24163969212768033, 'max_depth': 7.1014498228622465, 'n_estimators': 130.09474195295505, 'scale_pos_weight': 12.725798119272547}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.18253968253968253]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.19003267973856208]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.28947245564892615]\n",
      "Final Test Score is 0.7254464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.4784433503380112, 'gamma': 48.7277970895084, 'learning_rate': 0.19273405390808196, 'max_depth': 3.015360921936093, 'n_estimators': 150.4339192219138, 'scale_pos_weight': 11.592190121250407}\n",
      "100%|█████████████████████████████████████████████| 100/100 [03:37<00:00,  2.18s/trial, best loss: 0.21428571428571422]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.28944911297852477]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.1922735760971055]\n",
      "Final Test Score is 0.8035714285714285\n",
      "best = {'a': 0, 'colsample_bytree': 0.6841032947647534, 'gamma': 12.358971671364749, 'learning_rate': 0.6830702103815577, 'max_depth': 1.9043354882307009, 'n_estimators': 108.22190712204946, 'scale_pos_weight': 14.527255593053367}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.2718253968253968]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.17243230625583564]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:29<00:00,  1.11trial/s, best loss: 0.2298085901027077]\n",
      "Final Test Score is 0.84375\n",
      "best = {'a': 0, 'colsample_bytree': 0.7231148486990305, 'gamma': 34.602022013258036, 'learning_rate': 0.7233555001205292, 'max_depth': 6.25821176848311, 'n_estimators': 153.56257529020093, 'scale_pos_weight': 10.386058647375881}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.32trial/s, best loss: 0.19642857142857148]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.2816760037348272]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.23004201680672273]\n",
      "Final Test Score is 0.8139880952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.23497496515826344, 'gamma': 11.472545979715015, 'learning_rate': 0.3115465560839986, 'max_depth': 4.213773078242847, 'n_estimators': 172.23060037731824, 'scale_pos_weight': 7.855144314303928}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:23<00:00,  1.19trial/s, best loss: 0.24603174603174605]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.13436041083099903]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.14040616246498602]\n",
      "Final Test Score is 0.7269345238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.5593558695486733, 'gamma': 39.48042500874189, 'learning_rate': 0.8836927243498404, 'max_depth': 6.637320216799713, 'n_estimators': 111.68595027179377, 'scale_pos_weight': 12.25778261492576}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:27<00:00,  1.14trial/s, best loss: 0.2023809523809524]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.21603641456582634]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.25744631185807654]\n",
      "Final Test Score is 0.7113095238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.3745457912540887, 'gamma': 16.060211717224064, 'learning_rate': 0.9042718088412005, 'max_depth': 1.8005114285676942, 'n_estimators': 128.3747731979814, 'scale_pos_weight': 13.441068106512812}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.1726190476190476]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.13858543417366945]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.2119281045751634]\n",
      "Final Test Score is 0.7358630952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.6326286298475998, 'gamma': 90.64121561342857, 'learning_rate': 0.4899128757365906, 'max_depth': 8.564841366358905, 'n_estimators': 132.70656607873678, 'scale_pos_weight': 12.383941002970875}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.20238095238095233]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.1982026143790849]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:06<00:00,  1.50trial/s, best loss: 0.3171101774042951]\n",
      "Final Test Score is 0.875\n",
      "best = {'a': 0, 'colsample_bytree': 0.4950865743129662, 'gamma': 17.71401950456311, 'learning_rate': 0.17775241750721932, 'max_depth': 2.831732398108821, 'n_estimators': 122.12013711278635, 'scale_pos_weight': 8.603389679286494}\n",
      "100%|█████████████████████████████████████████████████████████████| 100/100 [01:06<00:00,  1.49trial/s, best loss: 0.5]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.28508403361344536]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.19211017740429503]\n",
      "Final Test Score is 0.7514880952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.47346664512393144, 'gamma': 37.512657086964424, 'learning_rate': 0.9925370958670349, 'max_depth': 9.341550000711104, 'n_estimators': 132.49677443590969, 'scale_pos_weight': 7.004748736229222}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.23809523809523814]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.23162931839402423]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.1763071895424836]\n",
      "Final Test Score is 0.742559523809524\n",
      "best = {'a': 0, 'colsample_bytree': 0.24981530300690857, 'gamma': 11.211924250617304, 'learning_rate': 0.051734598955549244, 'max_depth': 7.193226959835224, 'n_estimators': 117.47530094463039, 'scale_pos_weight': 7.02949353618052}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.16468253968253968]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.25982726423902897]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.25772642390289446]\n",
      "Final Test Score is 0.7269345238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.20667953131004252, 'gamma': 15.557940734843442, 'learning_rate': 0.7575469821302456, 'max_depth': 8.662413621219208, 'n_estimators': 118.58297114091104, 'scale_pos_weight': 8.493948511466808}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.20436507936507933]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.20616246498599436]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.22787114845938372]\n",
      "Final Test Score is 0.6175595238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.576501907728886, 'gamma': 29.02362281053539, 'learning_rate': 0.9061411240573033, 'max_depth': 7.2325855069398735, 'n_estimators': 199.6911837507948, 'scale_pos_weight': 13.160873162270583}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.24999999999999992]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.2356442577030812]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.2556022408963585]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.6906084947093911, 'gamma': 11.475302752271773, 'learning_rate': 0.41089988755403084, 'max_depth': 3.501072177671774, 'n_estimators': 173.29044146035523, 'scale_pos_weight': 11.288261684039838}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.2817460317460318]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:29<00:00,  1.12trial/s, best loss: 0.2439075630252101]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19trial/s, best loss: 0.20819327731092438]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.6019798408065465, 'gamma': 20.188923919747175, 'learning_rate': 0.7094251553973546, 'max_depth': 7.100404022661848, 'n_estimators': 190.60714343579707, 'scale_pos_weight': 9.09954537721043}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.22222222222222218]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.18022875816993458]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43trial/s, best loss: 0.10298786181139123]\n",
      "Final Test Score is 0.6346726190476191\n",
      "best = {'a': 0, 'colsample_bytree': 0.5622882654861873, 'gamma': 41.8091494299468, 'learning_rate': 0.5595791316002855, 'max_depth': 5.988017673732551, 'n_estimators': 198.38088743061616, 'scale_pos_weight': 9.560757264620019}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:29<00:00,  1.12trial/s, best loss: 0.2123015873015872]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.2022175536881419]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.17250233426704017]\n",
      "Final Test Score is 0.8541666666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.5919031045546236, 'gamma': 10.570314660554992, 'learning_rate': 0.44142586403323725, 'max_depth': 5.86509781024495, 'n_estimators': 151.0672076116661, 'scale_pos_weight': 10.347801978238895}\n",
      "100%|██████████████████████████████████████████| 100/100 [16:31:50<00:00, 595.11s/trial, best loss: 0.1904761904761905]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.49trial/s, best loss: 0.20816993464052283]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.29946311858076563]\n",
      "Final Test Score is 0.890625\n",
      "best = {'a': 0, 'colsample_bytree': 0.20343403308952876, 'gamma': 18.637685907611647, 'learning_rate': 0.926274486944995, 'max_depth': 4.925477225219835, 'n_estimators': 180.7828682636162, 'scale_pos_weight': 11.634472551952769}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:36<00:00,  1.03trial/s, best loss: 0.20436507936507933]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.1644024276377217]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:27<00:00,  1.15trial/s, best loss: 0.22978524743230624]\n",
      "Final Test Score is 0.6815476190476191\n",
      "best = {'a': 0, 'colsample_bytree': 0.9720019153804577, 'gamma': 20.91610683067333, 'learning_rate': 0.30860001201598725, 'max_depth': 9.89204623092872, 'n_estimators': 167.77252278830568, 'scale_pos_weight': 14.877767119330922}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.26785714285714285]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.18639122315592907]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.2260971055088703]\n",
      "Final Test Score is 0.7477678571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.9808391034710332, 'gamma': 10.74721707971787, 'learning_rate': 0.9997503923728944, 'max_depth': 8.310428181312979, 'n_estimators': 161.82609111357078, 'scale_pos_weight': 12.304766407541429}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.15674603174603177]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.16456582633053227]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.2736928104575163]\n",
      "Final Test Score is 0.7165178571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.8388945021880785, 'gamma': 10.600082232949092, 'learning_rate': 0.5118233573465545, 'max_depth': 1.0198159105232891, 'n_estimators': 148.9163506265251, 'scale_pos_weight': 11.384232931979664}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.18650793650793648]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.13267973856209145]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.20200746965452843]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.7161233216211165, 'gamma': 30.569101685948326, 'learning_rate': 0.33196951188012214, 'max_depth': 6.796999328778421, 'n_estimators': 148.15679723408337, 'scale_pos_weight': 11.752107335747354}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.2023809523809524]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.41trial/s, best loss: 0.23363678804855273]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19trial/s, best loss: 0.1983193277310925]\n",
      "Final Test Score is 0.7061011904761906\n",
      "best = {'a': 0, 'colsample_bytree': 0.830627904232354, 'gamma': 23.87019940947281, 'learning_rate': 0.6289143717820562, 'max_depth': 7.655356214759148, 'n_estimators': 107.91474664229466, 'scale_pos_weight': 13.21615421965185}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:06<00:00,  1.50trial/s, best loss: 0.20436507936507928]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.22210550887021474]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.15438842203548087]\n",
      "Final Test Score is 0.7619047619047621\n",
      "best = {'a': 0, 'colsample_bytree': 0.9716804964056672, 'gamma': 15.490086136910358, 'learning_rate': 0.10472781357788787, 'max_depth': 1.7437564778078736, 'n_estimators': 132.04148038753095, 'scale_pos_weight': 14.585268065440006}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.19246031746031744]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19trial/s, best loss: 0.2259803921568627]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.2240429505135388]\n",
      "Final Test Score is 0.8177083333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.652801075027303, 'gamma': 93.90174492251685, 'learning_rate': 0.22055396139351638, 'max_depth': 5.835853349455598, 'n_estimators': 161.00229111844885, 'scale_pos_weight': 11.528144793774807}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.20238095238095233]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.194140989729225]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.259780578898226]\n",
      "Final Test Score is 0.5930059523809523\n",
      "best = {'a': 0, 'colsample_bytree': 0.20095921224600322, 'gamma': 73.6383733612319, 'learning_rate': 0.6944472670428732, 'max_depth': 2.5601003182819504, 'n_estimators': 159.35771707809246, 'scale_pos_weight': 11.509995784185964}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.24404761904761904]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:03<00:00,  1.57trial/s, best loss: 0.15840336134453772]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.28trial/s, best loss: 0.23765172735760967]\n",
      "Final Test Score is 0.8191964285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.7755031073948314, 'gamma': 16.82290327868247, 'learning_rate': 0.8593739967560953, 'max_depth': 3.992102101507516, 'n_estimators': 158.35448480410977, 'scale_pos_weight': 5.756708111470032}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.1686507936507936]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.24556489262371614]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.1942577030812325]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.8865618635686094, 'gamma': 31.47749998403045, 'learning_rate': 0.6914104982946222, 'max_depth': 2.6625123012271157, 'n_estimators': 123.44860288476096, 'scale_pos_weight': 13.234631592409777}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:06<00:00,  1.49trial/s, best loss: 0.18055555555555555]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.1664098972922502]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.14859943977591028]\n",
      "Final Test Score is 0.7217261904761906\n",
      "best = {'a': 0, 'colsample_bytree': 0.6095558869881642, 'gamma': 11.950233939498958, 'learning_rate': 0.2541855726101828, 'max_depth': 4.189803339628054, 'n_estimators': 124.97129906044836, 'scale_pos_weight': 14.012663110010383}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.41trial/s, best loss: 0.19047619047619047]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.1941176470588235]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.16853408029878622]\n",
      "Final Test Score is 0.8035714285714285\n",
      "best = {'a': 0, 'colsample_bytree': 0.3802271238713458, 'gamma': 13.44944846992678, 'learning_rate': 0.39230447093268883, 'max_depth': 7.8032113384021, 'n_estimators': 102.24093643156077, 'scale_pos_weight': 13.307463719841742}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.23809523809523803]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.15060690943043883]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.2814192343604108]\n",
      "Final Test Score is 0.8541666666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.5825229179803931, 'gamma': 29.77419270063183, 'learning_rate': 0.1507305581353524, 'max_depth': 2.0721919205840127, 'n_estimators': 193.11084353901146, 'scale_pos_weight': 12.706933256789785}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43trial/s, best loss: 0.20634920634920628]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.21977124183006533]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.33trial/s, best loss: 0.14073295985060685]\n",
      "Final Test Score is 0.8333333333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.4297203786596091, 'gamma': 96.65396609825062, 'learning_rate': 0.9317635235547402, 'max_depth': 3.0781575529061254, 'n_estimators': 188.3698199045931, 'scale_pos_weight': 12.88312954486257}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.1964285714285714]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2777544351073763]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:14<00:00,  1.33trial/s, best loss: 0.2454948646125116]\n",
      "Final Test Score is 0.7686011904761906\n",
      "best = {'a': 0, 'colsample_bytree': 0.30534297123076676, 'gamma': 89.97698097422668, 'learning_rate': 0.8451341998406001, 'max_depth': 8.873749819454106, 'n_estimators': 127.16151901186225, 'scale_pos_weight': 10.580161573329743}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.2559523809523809]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.19584500466853408]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.17824463118580766]\n",
      "Final Test Score is 0.7373511904761905\n",
      "best = {'a': 0, 'colsample_bytree': 0.5911011929599372, 'gamma': 49.4524492564243, 'learning_rate': 0.9170289141041966, 'max_depth': 6.6098374677236995, 'n_estimators': 144.3559230427108, 'scale_pos_weight': 7.500651029824349}\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43trial/s, best loss: 0.255952380952381]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:27<00:00,  1.15trial/s, best loss: 0.17028478057889826]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2692810457516339]\n",
      "Final Test Score is 0.793154761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.4384897044799878, 'gamma': 13.546158863760246, 'learning_rate': 0.013909145429998868, 'max_depth': 9.67536904558094, 'n_estimators': 197.69760415987992, 'scale_pos_weight': 14.592143143041504}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.2123015873015873]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.14864612511671335]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.19225023342670397]\n",
      "Final Test Score is 0.6257440476190477\n",
      "best = {'a': 0, 'colsample_bytree': 0.5307582028264262, 'gamma': 11.045115683502436, 'learning_rate': 0.40392139407795175, 'max_depth': 5.657483404663469, 'n_estimators': 183.44283735691633, 'scale_pos_weight': 10.762192260625648}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.17063492063492058]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.21220821661998127]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.20994397759103642]\n",
      "Final Test Score is 0.8191964285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.6560461708328307, 'gamma': 16.073016873937746, 'learning_rate': 0.7177634813663859, 'max_depth': 4.503417762370068, 'n_estimators': 100.27567033304501, 'scale_pos_weight': 14.56800056870033}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.11111111111111109]\n",
      "100%|████████████████████████████████████████████| 100/100 [1:55:46<00:00, 69.46s/trial, best loss: 0.2176470588235294]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:56<00:00,  1.76trial/s, best loss: 0.14059290382819797]\n",
      "Final Test Score is 0.6592261904761905\n",
      "best = {'a': 0, 'colsample_bytree': 0.22000970534245384, 'gamma': 105.15573337774988, 'learning_rate': 0.924975840269717, 'max_depth': 4.060415045730517, 'n_estimators': 145.91740363723602, 'scale_pos_weight': 14.972891476383378}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:01<00:00,  1.62trial/s, best loss: 0.3174603174603174]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.20387488328664796]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.23580765639589166]\n",
      "Final Test Score is 0.793154761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.7097784708050486, 'gamma': 11.918635672344662, 'learning_rate': 0.02736851908031579, 'max_depth': 3.4731555185286878, 'n_estimators': 191.93498267365302, 'scale_pos_weight': 8.834478322375077}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.2976190476190476]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.22413632119514473]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.197922502334267]\n",
      "Final Test Score is 0.859375\n",
      "best = {'a': 0, 'colsample_bytree': 0.9150815183249519, 'gamma': 32.64004094689757, 'learning_rate': 0.1539313575686146, 'max_depth': 5.588958451488484, 'n_estimators': 172.84116783681245, 'scale_pos_weight': 8.426755384536104}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.15674603174603172]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.1622082166199813]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:07<00:00,  1.49trial/s, best loss: 0.1447012138188609]\n",
      "Final Test Score is 0.6294642857142857\n",
      "best = {'a': 0, 'colsample_bytree': 0.6892600679865761, 'gamma': 11.495231584414682, 'learning_rate': 0.2751041106016541, 'max_depth': 1.7740698703502173, 'n_estimators': 107.34423659046995, 'scale_pos_weight': 10.437678191674463}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.1884920634920635]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.19603174603174603]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.18636788048552755]\n",
      "Final Test Score is 0.7864583333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.8908648298601022, 'gamma': 106.15177317525243, 'learning_rate': 0.47022522852935483, 'max_depth': 4.889233113992872, 'n_estimators': 145.25489473214063, 'scale_pos_weight': 14.299818525109348}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.18650793650793648]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.20014005602240892]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.18228291316526604]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.6690086138167709, 'gamma': 52.97316732827828, 'learning_rate': 0.9516644503276319, 'max_depth': 8.857292026819454, 'n_estimators': 186.62026656645588, 'scale_pos_weight': 6.05096166817121}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.20634920634920637]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.19014939309056952]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2081232492997199]\n",
      "Final Test Score is 0.84375\n",
      "best = {'a': 0, 'colsample_bytree': 0.2241690096438454, 'gamma': 19.77927328576, 'learning_rate': 0.38569981795647146, 'max_depth': 9.95046525967555, 'n_estimators': 155.80271155299673, 'scale_pos_weight': 11.258738757892132}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.27579365079365076]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.25378151260504195]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.29516806722689076]\n",
      "Final Test Score is 0.7619047619047621\n",
      "best = {'a': 0, 'colsample_bytree': 0.3584874203787227, 'gamma': 91.23240728244387, 'learning_rate': 0.12412988713661927, 'max_depth': 3.608688037378097, 'n_estimators': 125.7843664974019, 'scale_pos_weight': 13.58848850633225}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.2083333333333333]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.2260737628384687]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.11106442577030813]\n",
      "Final Test Score is 0.7619047619047621\n",
      "best = {'a': 0, 'colsample_bytree': 0.41492881827919076, 'gamma': 31.344748465704278, 'learning_rate': 0.8619731554741805, 'max_depth': 4.31695152261987, 'n_estimators': 119.34240070572845, 'scale_pos_weight': 11.687173329280398}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.25trial/s, best loss: 0.34920634920634924]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.45trial/s, best loss: 0.17612044817927172]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.22009803921568627]\n",
      "Final Test Score is 0.7619047619047621\n",
      "best = {'a': 0, 'colsample_bytree': 0.2702890923493465, 'gamma': 43.370829466057344, 'learning_rate': 0.47892423565188097, 'max_depth': 7.3676322366323985, 'n_estimators': 106.78743533632819, 'scale_pos_weight': 13.97603842587854}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.19841269841269837]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:04<00:00,  1.56trial/s, best loss: 0.17836134453781508]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.1644491129785248]\n",
      "Final Test Score is 0.7827380952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.5830379512552559, 'gamma': 15.074573680019983, 'learning_rate': 0.21426623455552624, 'max_depth': 1.3360571015311904, 'n_estimators': 133.59288974720434, 'scale_pos_weight': 11.90558406556074}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.22619047619047614]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:10<00:00,  1.43trial/s, best loss: 0.2398692810457516]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.11269841269841267]\n",
      "Final Test Score is 0.730654761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.5968942297994188, 'gamma': 61.30692871049872, 'learning_rate': 0.9019705434425723, 'max_depth': 5.868737409149734, 'n_estimators': 187.84646707181054, 'scale_pos_weight': 8.103005238638405}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.1706349206349206]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.15816993464052284]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.23751167133520076]\n",
      "Final Test Score is 0.6800595238095238\n",
      "best = {'a': 0, 'colsample_bytree': 0.6675112543489827, 'gamma': 39.57270937241142, 'learning_rate': 0.39252452067611077, 'max_depth': 8.127344495236617, 'n_estimators': 116.73350121206236, 'scale_pos_weight': 14.917759177060182}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.1845238095238095]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.28541083099906633]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.2955182072829132]\n",
      "Final Test Score is 0.7671130952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.6104412653433375, 'gamma': 12.734629964232752, 'learning_rate': 0.15735399412653012, 'max_depth': 1.5788400536848313, 'n_estimators': 167.47757914266356, 'scale_pos_weight': 9.91772253470501}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.2202380952380952]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.22210550887021474]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.26372549019607844]\n",
      "Final Test Score is 0.8400297619047619\n",
      "best = {'a': 0, 'colsample_bytree': 0.832148199104906, 'gamma': 19.800273759786645, 'learning_rate': 0.6354650728444253, 'max_depth': 9.27876912509749, 'n_estimators': 196.5811774738297, 'scale_pos_weight': 8.728238970622307}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.18849206349206346]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.20429505135387485]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.253734827264239]\n",
      "Final Test Score is 0.7723214285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.7192845864577706, 'gamma': 59.52648959134268, 'learning_rate': 0.986750431641557, 'max_depth': 8.829424507931236, 'n_estimators': 127.2921529720555, 'scale_pos_weight': 10.685364645687638}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.23015873015873015]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.2653828197945845]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.2001867413632119]\n",
      "Final Test Score is 0.8125\n",
      "best = {'a': 0, 'colsample_bytree': 0.6607127111738762, 'gamma': 39.03830370482935, 'learning_rate': 0.06307583814298795, 'max_depth': 8.813072405430473, 'n_estimators': 150.4204153274913, 'scale_pos_weight': 14.082734924714396}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.15277777777777776]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.20602240896358537]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.43trial/s, best loss: 0.25753968253968257]\n",
      "Final Test Score is 0.7165178571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.6697688489373725, 'gamma': 11.57128444908366, 'learning_rate': 0.37527266869685744, 'max_depth': 2.7196357388535524, 'n_estimators': 189.75050531596332, 'scale_pos_weight': 14.834811289261872}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16trial/s, best loss: 0.1527777777777777]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.27163865546218485]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.17808123249299715]\n",
      "Final Test Score is 0.8489583333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.20328078017642326, 'gamma': 11.846426400810268, 'learning_rate': 0.11675987435133489, 'max_depth': 1.5849175558952833, 'n_estimators': 181.15845501431733, 'scale_pos_weight': 10.065279469280773}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.22023809523809523]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.17453314659197008]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.1761671335200747]\n",
      "Final Test Score is 0.7477678571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.37583912852430956, 'gamma': 21.819199064131407, 'learning_rate': 0.9848134732525058, 'max_depth': 3.368455473253592, 'n_estimators': 174.58253505990706, 'scale_pos_weight': 11.06471796126982}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.21428571428571433]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.2597805788982259]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:04<00:00,  1.55trial/s, best loss: 0.2080765639589169]\n",
      "Final Test Score is 0.8541666666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.3422888408662215, 'gamma': 15.018254289761309, 'learning_rate': 0.4177997256920958, 'max_depth': 1.036667644385575, 'n_estimators': 113.486298365622, 'scale_pos_weight': 14.688230179695994}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.21626984126984128]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.21988795518207283]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.25943043884220357]\n",
      "Final Test Score is 0.8385416666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.7820015250463146, 'gamma': 96.72793798515912, 'learning_rate': 0.45043724043482347, 'max_depth': 1.7785078752991663, 'n_estimators': 123.3563411434953, 'scale_pos_weight': 13.595422472665177}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.22023809523809532]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.12693744164332402]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.2418767507002801]\n",
      "Final Test Score is 0.5736607142857143\n",
      "best = {'a': 0, 'colsample_bytree': 0.5190138343554772, 'gamma': 27.521937081694016, 'learning_rate': 0.5310801729619222, 'max_depth': 7.149524012244683, 'n_estimators': 142.7723689322136, 'scale_pos_weight': 10.423469064226662}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.28trial/s, best loss: 0.2757936507936508]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.23592436974789918]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.11893090569561156]\n",
      "Final Test Score is 0.8854166666666667\n",
      "best = {'a': 0, 'colsample_bytree': 0.3196923929300858, 'gamma': 39.43599802055519, 'learning_rate': 0.5204879084848442, 'max_depth': 5.289298490835741, 'n_estimators': 164.33823419866118, 'scale_pos_weight': 12.668791277417633}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19trial/s, best loss: 0.17857142857142858]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.19806255835667605]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.20023342670401492]\n",
      "Final Test Score is 0.730654761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.577087719899692, 'gamma': 78.49169700473517, 'learning_rate': 0.5143658306925392, 'max_depth': 5.495596255575675, 'n_estimators': 178.35974216995282, 'scale_pos_weight': 14.6849882659924}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.3115079365079365]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.21185807656395886]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.2259103641456582]\n",
      "Final Test Score is 0.8020833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.7368086874541211, 'gamma': 112.14351841377896, 'learning_rate': 0.10630537726611064, 'max_depth': 3.294608105449694, 'n_estimators': 171.5781670929662, 'scale_pos_weight': 13.169181262278434}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.37896825396825395]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.21610644257703074]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.16832399626517272]\n",
      "Final Test Score is 0.746279761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.5356089550201705, 'gamma': 76.23132763063941, 'learning_rate': 0.18715197098361716, 'max_depth': 7.923705095567973, 'n_estimators': 137.90569125595405, 'scale_pos_weight': 14.973407245180503}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.21031746031746026]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.2097572362278244]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.16458916900093376]\n",
      "Final Test Score is 0.8244047619047619\n",
      "best = {'a': 0, 'colsample_bytree': 0.9990851347931315, 'gamma': 25.55713387620805, 'learning_rate': 0.38623109683681967, 'max_depth': 3.7292636747210555, 'n_estimators': 166.60208729658314, 'scale_pos_weight': 8.969958653458956}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.16666666666666663]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.22973856209150326]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.37trial/s, best loss: 0.2911531279178338]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.4671925682525603, 'gamma': 11.686031091817995, 'learning_rate': 0.18966319509427487, 'max_depth': 5.493531288734847, 'n_estimators': 168.55464796745886, 'scale_pos_weight': 10.99382662243604}\n"
     ]
    }
   ],
   "source": [
    "### get out a list *primary_parameters* that has the parameters and aucs\n",
    "\n",
    "for i in range(100):\n",
    "    data = no_cutoff\n",
    "    do_nested_cv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfaafa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary pickle file \n",
    "f = open(\"cutoff analysis/zero parameters.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(primary_parameters,f)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0fa5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_parameters = pd.read_pickle(r'cutoff analysis/zero parameters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc009871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take these parameters to R\n",
    "param_top_ten = sorted(zero_parameters, key = lambda x: x[1])[-10:]\n",
    "params = [a[0] for a in param_top_ten]\n",
    "param_df = pd.DataFrame(params).drop(columns = ['a'])\n",
    "param_df.to_csv('cutoff analysis/zero top 10 parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02840569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median AUC: 0.8820684523809523\n",
      "mean AUC: 0.8738616071428572\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#FOR EACH OF THE 10 BEST PERFORMING PARAMETERS IN ORIGINAL_MODELS, DO EVALUATIONS ON 10 RANDOM STATE SPLITS\n",
    "####\n",
    "\n",
    "param_dict = param_top_ten\n",
    "auc_list = []\n",
    "data = no_cutoff\n",
    "\n",
    "for x in range(10):\n",
    "    params = {'max_depth': int(param_dict[x][0]['max_depth']), 'gamma': param_dict[x][0]['gamma'],\n",
    "                              'learning_rate': param_dict[x][0]['learning_rate'], 'n_estimators': int(param_dict[x][0]['n_estimators']),\n",
    "                              'scale_pos_weight': int(param_dict[x][0]['scale_pos_weight']), 'colsample_bytree': param_dict[x][0]['colsample_bytree']}\n",
    "    X = data.iloc[:,:-1] # Feature matrix in pd.DataFrame format\n",
    "    y = data.iloc[:,-1] # Target vector in pd.Series format\n",
    "    \n",
    "    for q in range(10):\n",
    "\n",
    "        # Making train and test sets for both X and y\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "        # Instantiate an XGBoost object with hyperparameters\n",
    "        xgb_clf = xgb.XGBClassifier(**params,\n",
    "                                    objective='binary:logistic', booster='gbtree', \n",
    "                                    n_jobs=2, eval_metric = 'logloss', use_label_encoder=False)\n",
    "\n",
    "        # Train the model with train data sets\n",
    "        xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "        prob = np.array(pd.DataFrame(xgb_clf.predict_proba(X_test))[1])\n",
    "        for x in range(len(prob)):\n",
    "            if prob[x] > np.mean(np.array(pd.DataFrame(xgb_clf.predict_proba(X_test))[1])):\n",
    "                prob[x] = 1\n",
    "            else:\n",
    "                prob[x] = 0\n",
    "\n",
    "        y_pred = prob\n",
    "        y_true = y_test # True values\n",
    "\n",
    "#         print(\"Accuracy: \", np.round(accuracy_score(y_true, y_pred), 3))\n",
    "\n",
    "        auc_list.append(roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "        #less ugly step curve\n",
    "#         plot_roc_curve(xgb_clf, X_test, y_test, color='lightgrey', ax=ax)\n",
    "\n",
    "# ax.get_legend().remove()\n",
    "# print(auc_list)\n",
    "print('median AUC: ' + str(np.median(auc_list)))\n",
    "print('mean AUC: ' + str(np.mean(auc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "726bf36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard error 0.00702237770560606\n",
      "std 0.0702237770560606\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import sem\n",
    "print(\"standard error\", sem(auc_list))\n",
    "print(\"std\", np.std(auc_list, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5feba787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from the 10 best models, 100 aucs in a histogram\n",
    "sns.displot(auc_list, bins = 15, color='lightblue')\n",
    "plt.xlabel('AUC Score')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.title('Nested Cross Validation AUC Scores', fontsize = 15)\n",
    "\n",
    "#median = 0.882\n",
    "#mean = 0.880\n",
    "plt.savefig('cutoff analysis/zero auc scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "099b996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 iterations using random state and 10 best params\n",
    "#for each best param, do 10 predictions using random states\n",
    "\n",
    "data = no_cutoff\n",
    "param_dict = sorted(param_top_ten, key = lambda x: x[1])[-10:]\n",
    "prediction_matrix = pd.DataFrame(original_clean.reset_index()['species'])  \n",
    "models_list_proven = []\n",
    "\n",
    "for x in range(10):\n",
    "    params = {'max_depth': int(param_dict[x][0]['max_depth']), 'gamma': param_dict[x][0]['gamma'],\n",
    "                              'learning_rate': param_dict[x][0]['learning_rate'], 'n_estimators': int(param_dict[x][0]['n_estimators']),\n",
    "                              'scale_pos_weight': int(param_dict[x][0]['scale_pos_weight']), 'colsample_bytree': param_dict[x][0]['colsample_bytree']}\n",
    "    \n",
    "    for u in range(10):\n",
    "        X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "        #stratify to make sure the 1s are distributed evenly\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "        \n",
    "        model = XGBClassifier(**params, booster='gbtree', objective='binary:logistic', eval_metric = 'logloss', use_label_encoder=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        models_list_proven.append(model)\n",
    "\n",
    "        #predictions in an array\n",
    "        y = model.predict_proba(X)\n",
    "\n",
    "        #match prediction to the species for this split\n",
    "        probability_table = X.reset_index() #get the species in the test set\n",
    "        probability_table['probability'] = pd.DataFrame(pd.DataFrame(y)[1]) #get the probabilities\n",
    "        probability_table = probability_table[['species', 'probability']]\n",
    "        #put the prediction in the big df\n",
    "        for a in range(len(prediction_matrix)):\n",
    "            for b in range(len(probability_table)):\n",
    "                if prediction_matrix.loc[a, 'species'] == probability_table.loc[b, 'species']:\n",
    "                    prediction_matrix.loc[a, str(x) + '.' + str(u)] = probability_table.loc[b, 'probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57438e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>probability</th>\n",
       "      <th>std</th>\n",
       "      <th>percentile</th>\n",
       "      <th>potential/proven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bichromomyia flaviscutellata</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nyssomyia whitmani</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.998</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Psychodopygus carrerai</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.996</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nyssomyia intermedia</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.994</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Psathyromyia (Psathyromyia) shannoni</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.992</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Evandromyia (Evandromyia) wilsoni</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Brumptomyia orlandoi</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Brumptomyia mangabeirai</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Brumptomyia bragai</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Migonemyia (Blancasmyia) cerqueirai</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  species  probability    std  percentile  \\\n",
       "0            Bichromomyia flaviscutellata        0.943  0.050       1.000   \n",
       "1                      Nyssomyia whitmani        0.917  0.044       0.998   \n",
       "2                  Psychodopygus carrerai        0.916  0.055       0.996   \n",
       "3                    Nyssomyia intermedia        0.914  0.043       0.994   \n",
       "4    Psathyromyia (Psathyromyia) shannoni        0.912  0.066       0.992   \n",
       "..                                    ...          ...    ...         ...   \n",
       "507     Evandromyia (Evandromyia) wilsoni        0.057  0.033       0.011   \n",
       "508                  Brumptomyia orlandoi        0.056  0.037       0.006   \n",
       "509               Brumptomyia mangabeirai        0.056  0.037       0.006   \n",
       "510                    Brumptomyia bragai        0.056  0.037       0.006   \n",
       "511   Migonemyia (Blancasmyia) cerqueirai        0.056  0.033       0.002   \n",
       "\n",
       "     potential/proven  \n",
       "0                 2.0  \n",
       "1                 2.0  \n",
       "2                 2.0  \n",
       "3                 2.0  \n",
       "4                 2.0  \n",
       "..                ...  \n",
       "507               0.0  \n",
       "508               0.0  \n",
       "509               0.0  \n",
       "510               0.0  \n",
       "511               0.0  \n",
       "\n",
       "[512 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a prediction table with the median probability and percentile for each species\n",
    "prediction_matrix['std'] = pd.DataFrame(prediction_matrix.std(axis=1))\n",
    "prediction_matrix['probability'] = pd.DataFrame(prediction_matrix.median(axis=1))\n",
    "top_predictions = prediction_matrix\n",
    "top_predictions['percentile'] = top_predictions.probability.rank(pct=True)\n",
    "\n",
    "#these are the sandflies where the probability its a vector is greater than 0.5\n",
    "#top_predictions = top_predictions[top_predictions['probability'] >= 0.5].reset_index(drop=True)\n",
    "\n",
    "#get the important stats only\n",
    "top_predictions = top_predictions[['species', 'probability','std', 'percentile']].reset_index(drop=True)\n",
    "\n",
    "#add real labels\n",
    "top_predictions = getstatus(top_predictions, 'leish')\n",
    "top_predictions = top_predictions.fillna(0)\n",
    "\n",
    "#sort by probability\n",
    "final_predictions = top_predictions.sort_values(by ='probability', ascending=False).reset_index(drop=True)\n",
    "final_predictions = final_predictions.round(3)\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d5dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final predictions\n",
    "final_predictions.to_csv(\"cutoff analysis/zero all predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb2a5ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>probability</th>\n",
       "      <th>std</th>\n",
       "      <th>percentile</th>\n",
       "      <th>potential/proven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Psychodopygus amazonensis</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.963</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nyssomyia antunesi</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.959</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Psychodopygus guyanensis</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Psychodopygus claustrei</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pintomyia (Pintomyia) pessoai</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.943</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Trichophoromyia auraensis</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Psathyromyia (Psathyromyia) bigeniculata</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Psychodopygus chagasi</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Trichophoromyia castanheirai</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Psathyromyia (Psathyromyia) lanei</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Sciopemyia sordellii</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.916</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Brumptomyia avellari</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Warileya rotundipennis</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Evandromyia (Evandromyia) infraspinosa</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Pressatia choti</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Micropygomyia (Sauromyia) venezuelensis</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Psychodopygus dorlinsis</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Psychodopygus lainsoni</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Lutzomyia (Lutzomyia) lichyi</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.898</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     species  probability    std  percentile  \\\n",
       "19                 Psychodopygus amazonensis        0.847  0.085       0.963   \n",
       "21                        Nyssomyia antunesi        0.839  0.089       0.959   \n",
       "24                  Psychodopygus guyanensis        0.803  0.113       0.953   \n",
       "26                   Psychodopygus claustrei        0.798  0.091       0.949   \n",
       "29             Pintomyia (Pintomyia) pessoai        0.787  0.150       0.943   \n",
       "32                 Trichophoromyia auraensis        0.761  0.154       0.938   \n",
       "34  Psathyromyia (Psathyromyia) bigeniculata        0.739  0.111       0.934   \n",
       "39                     Psychodopygus chagasi        0.646  0.167       0.924   \n",
       "41              Trichophoromyia castanheirai        0.598  0.170       0.920   \n",
       "42         Psathyromyia (Psathyromyia) lanei        0.598  0.169       0.918   \n",
       "43                      Sciopemyia sordellii        0.586  0.164       0.916   \n",
       "44                      Brumptomyia avellari        0.581  0.163       0.914   \n",
       "45                    Warileya rotundipennis        0.574  0.183       0.912   \n",
       "47    Evandromyia (Evandromyia) infraspinosa        0.568  0.198       0.907   \n",
       "48                           Pressatia choti        0.568  0.153       0.907   \n",
       "49   Micropygomyia (Sauromyia) venezuelensis        0.538  0.168       0.904   \n",
       "50                   Psychodopygus dorlinsis        0.534  0.189       0.902   \n",
       "51                    Psychodopygus lainsoni        0.523  0.177       0.900   \n",
       "52              Lutzomyia (Lutzomyia) lichyi        0.519  0.170       0.898   \n",
       "\n",
       "    potential/proven  \n",
       "19               1.0  \n",
       "21               1.0  \n",
       "24               0.0  \n",
       "26               0.0  \n",
       "29               1.0  \n",
       "32               1.0  \n",
       "34               0.0  \n",
       "39               0.0  \n",
       "41               0.0  \n",
       "42               0.0  \n",
       "43               1.0  \n",
       "44               0.0  \n",
       "45               0.0  \n",
       "47               0.0  \n",
       "48               0.0  \n",
       "49               0.0  \n",
       "50               0.0  \n",
       "51               0.0  \n",
       "52               1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get new predicted\n",
    "new_predicted = final_predictions[final_predictions['potential/proven']!=2]\n",
    "new_predicted = new_predicted[new_predicted['probability'] >= 0.5]\n",
    "new_predicted\n",
    "#how many non vectors did it predict to be a vector?\n",
    "# len(d[d['probability'] >= 0.5]) = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f26697ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the csv\n",
    "new_predicted.to_csv(\"cutoff analysis/zero new predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae6f7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in modelslist created in the predtable function, returns dataframe of variables and importances\n",
    "def var_impt(list_of_models):\n",
    "\n",
    "    impt_matrix = pd.DataFrame(list_of_models[0].feature_importances_, original_clean.columns[0:93])\n",
    "    for x in range(1, len(list_of_models)):\n",
    "        var_array = pd.DataFrame(list_of_models[x].feature_importances_, original_clean.columns[0:93])\n",
    "        impt_matrix[x] = var_array[0]\n",
    "        \n",
    "    var_impt_df = pd.DataFrame()\n",
    "    var_impt_df['feature'] = original_clean.columns[0:81]\n",
    "    var_impt_df = var_impt_df.set_index('feature')\n",
    "    for var in original_clean.columns[0:81]:\n",
    "        mean = impt_matrix.loc[var].mean()\n",
    "        var_impt_df.loc[var, 'importance'] = mean\n",
    "        std = impt_matrix.loc[var].std()\n",
    "        var_impt_df.loc[var, 'std'] = std\n",
    "\n",
    "    var_impt_df = var_impt_df.reset_index()\n",
    "    \n",
    "    return impt_matrix, var_impt_df.round(3).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75d26fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_impt_conf = var_impt(models_list_proven)[1]\n",
    "var_impt_conf['lower'] = var_impt_conf['importance'] - 1.96 * var_impt_conf['std'] / 10\n",
    "var_impt_conf['higher'] = var_impt_conf['importance'] + 1.96 * var_impt_conf['std'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1bc53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_impt_conf.reset_index(drop=True).to_csv(\"cutoff analysis/zero variable importance all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "944b3f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>std</th>\n",
       "      <th>lower</th>\n",
       "      <th>higher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>citations</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.160756</td>\n",
       "      <td>0.215244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>canopy</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.088988</td>\n",
       "      <td>0.127012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>flii</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.035752</td>\n",
       "      <td>0.070248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>genus_Bichromomyia</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.043552</td>\n",
       "      <td>0.058448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ghm</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.035396</td>\n",
       "      <td>0.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>genus_Pintomyia</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.034944</td>\n",
       "      <td>0.049056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no.lat.teeth</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.032572</td>\n",
       "      <td>0.049428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ecoregion.breadth</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.024748</td>\n",
       "      <td>0.039252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>semi.domestic</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>0.038820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>temp.range</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.022316</td>\n",
       "      <td>0.033684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>domestic</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.029232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>rainfall</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>0.023312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mh.oihd</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.022312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>seas.wint</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.022508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>subtribe_Psychodopygina</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.011492</td>\n",
       "      <td>0.020508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>temp</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.010296</td>\n",
       "      <td>0.019704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tree.cover</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>0.018508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mh.tt</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mh.flfs</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.015332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>water.perm.cover</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.017880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>seas.summ</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>0.014312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>evi</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.013136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>labrum.length</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.013136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>wind.speed</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.013116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A3_wingl</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.006060</td>\n",
       "      <td>0.011940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance    std     lower    higher\n",
       "38                citations       0.188  0.139  0.160756  0.215244\n",
       "53                   canopy       0.108  0.097  0.088988  0.127012\n",
       "51                     flii       0.053  0.088  0.035752  0.070248\n",
       "67       genus_Bichromomyia       0.051  0.038  0.043552  0.058448\n",
       "54                      ghm       0.045  0.049  0.035396  0.054604\n",
       "80          genus_Pintomyia       0.042  0.036  0.034944  0.049056\n",
       "42             no.lat.teeth       0.041  0.043  0.032572  0.049428\n",
       "62        ecoregion.breadth       0.032  0.037  0.024748  0.039252\n",
       "30            semi.domestic       0.030  0.045  0.021180  0.038820\n",
       "49               temp.range       0.028  0.029  0.022316  0.033684\n",
       "31                 domestic       0.021  0.042  0.012768  0.029232\n",
       "50                 rainfall       0.019  0.022  0.014688  0.023312\n",
       "27                  mh.oihd       0.018  0.022  0.013688  0.022312\n",
       "33                seas.wint       0.018  0.023  0.013492  0.022508\n",
       "66  subtribe_Psychodopygina       0.016  0.023  0.011492  0.020508\n",
       "48                     temp       0.015  0.024  0.010296  0.019704\n",
       "55               tree.cover       0.014  0.023  0.009492  0.018508\n",
       "21                    mh.tt       0.014  0.025  0.009100  0.018900\n",
       "16                  mh.flfs       0.012  0.017  0.008668  0.015332\n",
       "59         water.perm.cover       0.012  0.030  0.006120  0.017880\n",
       "34                seas.summ       0.010  0.022  0.005688  0.014312\n",
       "61                      evi       0.010  0.016  0.006864  0.013136\n",
       "39            labrum.length       0.010  0.016  0.006864  0.013136\n",
       "52               wind.speed       0.009  0.021  0.004884  0.013116\n",
       "41                 A3_wingl       0.009  0.015  0.006060  0.011940"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_impt_conf.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf0cbd",
   "metadata": {},
   "source": [
    "## 20 percent cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d47d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove: hs.canopy, hs.floor, peri, bites.man, bites.mammals, order.notes, labruml_wingl\n",
    "#         A3_wingl, dental.depth, wing.width\n",
    "    \n",
    "original = pd.read_csv('raw data/one hot encoded original data.csv')\n",
    "original = original.drop(columns=['Argentina', 'Belize','Bolivia', 'Brazil', 'Canada', 'CaymanIslands', 'Chile', 'Colombia',\n",
    "                                  'Costa.Rica', 'Cuba', 'Dominican.Republic', 'Ecuador', 'El.Salvador', 'French.Guiana',\n",
    "                                  'Guadeloupe', 'Guatemala', 'Grenada', 'Guyana', 'Haiti', 'Honduras', 'Jamaica','Martinica', \n",
    "                                  'Mexico', 'Nicaragua', 'Panama', 'Paraguay','PuertoRico', 'Peru', 'Suriname',\n",
    "                                  'TrinidadTobago', 'Uruguay', 'USA', 'Venezuela','VirginIslands'])\n",
    "status = pd.read_csv('raw data/sandfly status.csv')\n",
    "#if sandfly is a proven vector for any species of leish, mark it in a new column 'cl' as 1\n",
    "status['leish'] = 0\n",
    "for i in range(len(status)):\n",
    "    if 2 in status.values.tolist()[i]:\n",
    "        status.loc[i, 'leish'] = 2\n",
    "    elif 1 in status.values.tolist()[i]:\n",
    "        status.loc[i, 'leish'] = 1\n",
    "\n",
    "#get cleaned train datasets in a list\n",
    "parasite = 'leish'\n",
    "for j in range(len(original)):\n",
    "    for i in range(len(status)):\n",
    "        if original.loc[j, 'species'] == status.loc[i, 'species']:\n",
    "            original.loc[j, parasite] = status.loc[i, parasite]\n",
    "\n",
    "#fill the remaining vector status column with 0s, then binarize the status\n",
    "original[parasite] = original[parasite].fillna(0).map(lambda x : x//2)\n",
    "#set the index as the species name\n",
    "original = original.set_index('species', drop=True)\n",
    "#drop unnecessary columns\n",
    "original = original.drop(columns=['Unnamed: 0', 'bites.man'])\n",
    "\n",
    "####LOOK AT CORRELLATED VARIABLES\n",
    "#tribe_Hertigiini is corr w 'genus_Warileya'\n",
    "#subtribe_hertigiina is corr w 'genus_Warileya'\n",
    "#peri is corr w semi.domestic\n",
    "#'genus_Brumptomyia' is corr w 'subtribe_Brumptomyiina'\n",
    "#'genus_Micropygomyia' is corr w 'subtribe_Sergentomyiina'\n",
    "\n",
    "#wing_width / hs.canopy\n",
    "#wing_width / hs.floor\n",
    "#labruml_wingl / log.labrum.length\n",
    "#log.grass.cover / log.shrub.cover\n",
    "#domestic / intra\n",
    "#wing.width/temp \n",
    "#log.elevation / temp\n",
    "#log.temp.var / temp.range\n",
    "#maxshape_sabre / genus_Brumptomyia\n",
    "#log.dental.depth / log.labrum.length\n",
    "\n",
    "twenty_cutoff = original.drop(columns=['subtribe_Sergentomyiina', 'subtribe_Brumptomyiina',\n",
    "                                              'peri', 'subtribe_Hertigiina', 'tribe_Hertigiini',\n",
    "                                              'wing.width', 'labruml_wingl', 'log.shrub.cover',\n",
    "                                              'intra', 'log.elevation', 'log.temp.var', 'maxshape_sabre', 'log.dental.depth',\n",
    "                                       'hs.canopy', 'hs.floor', 'peri', 'bites.mammals',\n",
    "                                        'labruml_wingl', 'A3_wingl', 'wing.width'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1197752f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['b.tsmbf', 'b.tsdbf', 'b.tsgss', 'b.mangrove', 'b.fgs', 'b.dxs',\n",
       "       'b.tscf', 'b.tgss', 'b.tcforest', 'b.tbmforest', 'b.montane', 'mh.flfs',\n",
       "       'mh.ab', 'mh.bwa', 'mh.tttr', 'mh.th', 'mh.tt', 'mh.cr', 'mh.ca',\n",
       "       'mh.fwsl', 'mh.ma', 'mh.ada', 'mh.oihd', 'wild', 'semi.domestic',\n",
       "       'domestic', 'no.lat.teeth', 'wing.length', 'wingl_wingw', 'temp',\n",
       "       'temp.range', 'flii', 'canopy', 'ghm', 'evi', 'tribe_Phlebotomini',\n",
       "       'subtribe_Lutzomyiina', 'subtribe_Psychodopygina', 'genus_Bichromomyia',\n",
       "       'genus_Brumptomyia', 'genus_Dampfomyia', 'genus_Deanemyia',\n",
       "       'genus_Evandromyia', 'genus_Expapillata', 'genus_Hertigia',\n",
       "       'genus_Lutzomyia', 'genus_Martinsmyia', 'genus_Micropygomyia',\n",
       "       'genus_Migonemyia', 'genus_Nyssomyia', 'genus_Oligodontomyia',\n",
       "       'genus_Pintomyia', 'genus_Pressatia', 'genus_Psathyromyia',\n",
       "       'genus_Psychodopygus', 'genus_Sciopemyia', 'genus_Trichophoromyia',\n",
       "       'genus_Trichopygomyia', 'genus_Viannamyia', 'genus_Warileya',\n",
       "       'maxshape_spear', 'hypoteeth_rough', 'hypoteeth_smooth',\n",
       "       'hypoteeth_spiculate', 'log.citations', 'log.labrum.length',\n",
       "       'log.no.ven.teeth', 'log.no.cib.teeth', 'log.rainfall',\n",
       "       'log.wind.speed', 'log.tree.cover', 'log.crops.cover',\n",
       "       'log.grass.cover', 'log.urban.cover', 'log.water.perm.cover',\n",
       "       'log.water.seas.cover', 'log.ecoregion.breadth', 'leish'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_cutoff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "118ff19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:04<00:00,  1.56trial/s, best loss: 0.15079365079365079]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.21967787114845938]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.2198412698412698]\n",
      "Final Test Score is 0.8020833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.5867805713801237, 'gamma': 108.95283712600491, 'learning_rate': 0.43782796952587294, 'max_depth': 9.993787277467646, 'n_estimators': 145.29964238191684, 'scale_pos_weight': 13.427124986250638}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.2976190476190476]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.253781512605042]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:32<00:00,  1.08trial/s, best loss: 0.15655929038281977]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.8332631165251473, 'gamma': 10.381728652240266, 'learning_rate': 0.2782579685915095, 'max_depth': 5.939815473524851, 'n_estimators': 133.3259035500546, 'scale_pos_weight': 11.916282185253392}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.49trial/s, best loss: 0.20436507936507933]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:26<00:00,  1.15trial/s, best loss: 0.30735294117647066]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.22777777777777777]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.6886055155610311, 'gamma': 17.032541707486075, 'learning_rate': 0.7277084438957151, 'max_depth': 8.313631080589502, 'n_estimators': 199.15995719812807, 'scale_pos_weight': 12.317605794319533}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2797619047619047]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.45trial/s, best loss: 0.11886087768440705]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.21218487394957977]\n",
      "Final Test Score is 0.7269345238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.7617521740077764, 'gamma': 55.97495181381645, 'learning_rate': 0.8772172599138969, 'max_depth': 2.4320604597173276, 'n_estimators': 173.11582624008363, 'scale_pos_weight': 6.246168256690695}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.20634920634920637]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:06<00:00,  1.51trial/s, best loss: 0.15065359477124182]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.2256302521008403]\n",
      "Final Test Score is 0.6956845238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.6320471143613546, 'gamma': 78.00306387486916, 'learning_rate': 0.8843854425772065, 'max_depth': 8.160874171807112, 'n_estimators': 116.23171945187252, 'scale_pos_weight': 14.590188325468128}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.2718253968253968]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.14661531279178333]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.2141690009337068]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.7903520166814646, 'gamma': 43.85067543196449, 'learning_rate': 0.33091999676738254, 'max_depth': 5.184681285797466, 'n_estimators': 102.74379734055522, 'scale_pos_weight': 7.72277822385349}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.29166666666666663]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.23769841269841266]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.15637254901960784]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.8650845700255161, 'gamma': 10.409680536432045, 'learning_rate': 0.3145172679845206, 'max_depth': 4.522004504691022, 'n_estimators': 189.98759960714676, 'scale_pos_weight': 11.603356476506333}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.20238095238095236]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.25357142857142856]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.18trial/s, best loss: 0.22595704948646125]\n",
      "Final Test Score is 0.828125\n",
      "best = {'a': 0, 'colsample_bytree': 0.7478315557920039, 'gamma': 33.13964689517565, 'learning_rate': 0.35466082563725715, 'max_depth': 7.452519519494549, 'n_estimators': 159.5180151819634, 'scale_pos_weight': 11.742084419129721}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.20833333333333337]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.27trial/s, best loss: 0.17637721755368815]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.27163865546218485]\n",
      "Final Test Score is 0.84375\n",
      "best = {'a': 0, 'colsample_bytree': 0.41655086542053327, 'gamma': 16.834164987573846, 'learning_rate': 0.0612647792083912, 'max_depth': 2.264111339182802, 'n_estimators': 161.54590991362306, 'scale_pos_weight': 9.655284130406237}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:28<00:00,  1.14trial/s, best loss: 0.22817460317460314]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:27<00:00,  1.14trial/s, best loss: 0.2596171802054155]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.18trial/s, best loss: 0.22586367880485525]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.6645505504113397, 'gamma': 54.097934414822156, 'learning_rate': 0.9964118371930192, 'max_depth': 8.92537760237168, 'n_estimators': 158.18313157332722, 'scale_pos_weight': 5.304169272968422}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:26<00:00,  1.15trial/s, best loss: 0.24206349206349198]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.23578431372549016]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.12880485527544347]\n",
      "Final Test Score is 0.8385416666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.3687454814700441, 'gamma': 35.505176752652716, 'learning_rate': 0.14909867447596248, 'max_depth': 9.775219281835357, 'n_estimators': 100.02000216090342, 'scale_pos_weight': 14.724394053434276}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.26984126984126977]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.2042717086834734]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:34<00:00,  1.06trial/s, best loss: 0.259453781512605]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.7222396838867804, 'gamma': 31.31372531453883, 'learning_rate': 0.08549665600569435, 'max_depth': 2.7814032235515436, 'n_estimators': 192.86885784795058, 'scale_pos_weight': 14.126645668608878}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:32<00:00,  1.08trial/s, best loss: 0.23214285714285712]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:32<00:00,  1.09trial/s, best loss: 0.24591503267973858]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.21169467787114848]\n",
      "Final Test Score is 0.793154761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.6480033278057076, 'gamma': 29.15504702665646, 'learning_rate': 0.7440471896851335, 'max_depth': 6.5043614862390795, 'n_estimators': 172.0887801942446, 'scale_pos_weight': 9.551838759754464}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.24801587301587302]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:34<00:00,  1.06trial/s, best loss: 0.1803688141923436]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:33<00:00,  1.07trial/s, best loss: 0.1505368814192343]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.3575509132982135, 'gamma': 10.191440531011976, 'learning_rate': 0.4859353258902357, 'max_depth': 4.409359414552409, 'n_estimators': 199.33306519750982, 'scale_pos_weight': 11.665141087363214}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:30<00:00,  1.11trial/s, best loss: 0.24404761904761904]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.22990196078431369]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:32<00:00,  1.08trial/s, best loss: 0.2953781512605042]\n",
      "Final Test Score is 0.8229166666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.8379870467599356, 'gamma': 12.523167665014025, 'learning_rate': 0.27987095810206175, 'max_depth': 6.123397168555185, 'n_estimators': 174.97684513337302, 'scale_pos_weight': 13.22684248052381}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19trial/s, best loss: 0.25198412698412703]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.3212885154061625]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.11673669467787111]\n",
      "Final Test Score is 0.875\n",
      "best = {'a': 0, 'colsample_bytree': 0.22132818981613678, 'gamma': 11.674962817497875, 'learning_rate': 0.3693070782337321, 'max_depth': 1.0674364818159143, 'n_estimators': 194.5702243470501, 'scale_pos_weight': 6.76688724251462}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:32<00:00,  1.08trial/s, best loss: 0.17063492063492058]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.2181139122315593]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.2218720821661998]\n",
      "Final Test Score is 0.8139880952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.22535799464961465, 'gamma': 11.204438148080843, 'learning_rate': 0.12956290637089674, 'max_depth': 3.9539794280069898, 'n_estimators': 101.82552556137702, 'scale_pos_weight': 9.7620075373604}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:29<00:00,  1.11trial/s, best loss: 0.20833333333333337]\n",
      "100%|█████████████████████████████████████████████| 100/100 [02:05<00:00,  1.26s/trial, best loss: 0.19626517273576094]\n",
      "100%|█████████████████████████████████████████████| 100/100 [02:01<00:00,  1.21s/trial, best loss: 0.27929505135387483]\n",
      "Final Test Score is 0.7671130952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.6717859444437724, 'gamma': 41.502334007476435, 'learning_rate': 0.516908956356172, 'max_depth': 5.659737407977232, 'n_estimators': 140.80127524012266, 'scale_pos_weight': 12.200161932384887}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:37<00:00,  1.02trial/s, best loss: 0.23214285714285712]\n",
      "100%|██████████████████████████████████████████████| 100/100 [02:06<00:00,  1.26s/trial, best loss: 0.2393090569561157]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:44<00:00,  1.04s/trial, best loss: 0.2753734827264239]\n",
      "Final Test Score is 0.715029761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.5246081035455632, 'gamma': 76.70857999690222, 'learning_rate': 0.6515582617029497, 'max_depth': 8.534845917001185, 'n_estimators': 195.35139849053695, 'scale_pos_weight': 13.112272514763813}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:29<00:00,  1.11trial/s, best loss: 0.22619047619047616]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.19423436041083095]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.1605508870214752]\n",
      "Final Test Score is 0.6436011904761906\n",
      "best = {'a': 0, 'colsample_bytree': 0.8324463166153893, 'gamma': 103.33997379689875, 'learning_rate': 0.9044406037181625, 'max_depth': 7.167423636614395, 'n_estimators': 159.2518343911952, 'scale_pos_weight': 10.953758457479486}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:31<00:00,  1.10trial/s, best loss: 0.2738095238095238]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:54<00:00,  1.15s/trial, best loss: 0.22173202614379084]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:40<00:00,  1.01s/trial, best loss: 0.15835667600373485]\n",
      "Final Test Score is 0.7827380952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.4577256502902761, 'gamma': 12.471171069619288, 'learning_rate': 0.04867094840180365, 'max_depth': 5.548118778223749, 'n_estimators': 135.2764384824241, 'scale_pos_weight': 10.091280911907585}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.24404761904761907]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.25trial/s, best loss: 0.19803921568627447]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.2317226890756303]\n",
      "Final Test Score is 0.7879464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.8502330898856072, 'gamma': 10.852145369715885, 'learning_rate': 0.08985866978445822, 'max_depth': 1.232454604693063, 'n_estimators': 178.52063199716613, 'scale_pos_weight': 9.553080435117828}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.37trial/s, best loss: 0.2638888888888889]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:27<00:00,  1.14trial/s, best loss: 0.18429038281979457]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:30<00:00,  1.10trial/s, best loss: 0.21577964519140988]\n",
      "Final Test Score is 0.7827380952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.8003071264245432, 'gamma': 13.68888539465774, 'learning_rate': 0.9592857428717703, 'max_depth': 9.32231597106141, 'n_estimators': 111.91646141701666, 'scale_pos_weight': 11.102829630415604}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:52<00:00,  1.13s/trial, best loss: 0.16468253968253962]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:49<00:00,  1.10s/trial, best loss: 0.1782212885154061]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:31<00:00,  1.10trial/s, best loss: 0.2716619981325864]\n",
      "Final Test Score is 0.793154761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.4829961921112142, 'gamma': 40.72623311285008, 'learning_rate': 0.06944967095369226, 'max_depth': 3.1785389871722884, 'n_estimators': 116.91279451876493, 'scale_pos_weight': 12.363149086874152}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:48<00:00,  1.08s/trial, best loss: 0.20634920634920628]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.19trial/s, best loss: 0.19605508870214758]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.19614845938375347]\n",
      "Final Test Score is 0.7723214285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.6841427707495866, 'gamma': 12.008965730175081, 'learning_rate': 0.501960803334883, 'max_depth': 2.3406090029822026, 'n_estimators': 135.44147327982856, 'scale_pos_weight': 13.610514144529544}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.2162698412698413]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.21374883286647992]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.23767507002801117]\n",
      "Final Test Score is 0.8400297619047619\n",
      "best = {'a': 0, 'colsample_bytree': 0.41227272367213313, 'gamma': 30.435157590816356, 'learning_rate': 0.7371958669058234, 'max_depth': 5.573960266842394, 'n_estimators': 189.6829904098335, 'scale_pos_weight': 4.052365526952299}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:49<00:00,  1.09s/trial, best loss: 0.23809523809523803]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:52<00:00,  1.12s/trial, best loss: 0.21185807656395886]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:36<00:00,  1.04trial/s, best loss: 0.10700280112044813]\n",
      "Final Test Score is 0.7008928571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.7574195594108922, 'gamma': 54.05930118163323, 'learning_rate': 0.6889178159962227, 'max_depth': 4.197907024422029, 'n_estimators': 156.10188410340203, 'scale_pos_weight': 8.709448216787472}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:49<00:00,  1.09s/trial, best loss: 0.26587301587301587]\n",
      "100%|██████████████████████████████████████████████| 100/100 [02:02<00:00,  1.22s/trial, best loss: 0.2356442577030812]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:44<00:00,  1.04s/trial, best loss: 0.1803688141923436]\n",
      "Final Test Score is 0.7760416666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.2504695070758127, 'gamma': 91.44483358042638, 'learning_rate': 0.16000035549756686, 'max_depth': 9.845506358103096, 'n_estimators': 152.86420799668036, 'scale_pos_weight': 13.48056304081369}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.2539682539682539]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.22397292250233433]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.23760504201680666]\n",
      "Final Test Score is 0.7254464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.6233050609913772, 'gamma': 61.18022136919022, 'learning_rate': 0.9031998286384338, 'max_depth': 5.860252842036051, 'n_estimators': 138.3754965130411, 'scale_pos_weight': 9.94016227633663}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.26785714285714285]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:55<00:00,  1.16s/trial, best loss: 0.19624183006535945]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:49<00:00,  1.10s/trial, best loss: 0.25168067226890756]\n",
      "Final Test Score is 0.8489583333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.9018462884754513, 'gamma': 37.963806980665424, 'learning_rate': 0.11620891415951534, 'max_depth': 4.832257694822402, 'n_estimators': 193.07596781993504, 'scale_pos_weight': 9.789781861888706}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:51<00:00,  1.12s/trial, best loss: 0.20634920634920628]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:38<00:00,  1.02trial/s, best loss: 0.30147058823529416]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:23<00:00,  1.19trial/s, best loss: 0.23580765639589166]\n",
      "Final Test Score is 0.8035714285714285\n",
      "best = {'a': 0, 'colsample_bytree': 0.8166150639165065, 'gamma': 20.825751622373716, 'learning_rate': 0.9128163974676572, 'max_depth': 2.8811354913337435, 'n_estimators': 142.32166602616422, 'scale_pos_weight': 9.387819144990239}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.15873015873015872]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.17448646125116715]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.17406629318394026]\n",
      "Final Test Score is 0.6436011904761906\n",
      "best = {'a': 0, 'colsample_bytree': 0.34720897654382543, 'gamma': 125.23611587621336, 'learning_rate': 0.042064441730551405, 'max_depth': 1.4538996123712873, 'n_estimators': 172.44376450996046, 'scale_pos_weight': 14.354100860350602}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:30<00:00,  1.10trial/s, best loss: 0.2559523809523809]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:45<00:00,  1.05s/trial, best loss: 0.27156862745098037]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:29<00:00,  1.12trial/s, best loss: 0.15660597572362275]\n",
      "Final Test Score is 0.7269345238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.784900039736675, 'gamma': 57.91999695062502, 'learning_rate': 0.19196932951060058, 'max_depth': 3.62820527522339, 'n_estimators': 177.2625037284912, 'scale_pos_weight': 13.39123329252236}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:46<00:00,  1.07s/trial, best loss: 0.2876984126984127]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:46<00:00,  1.07s/trial, best loss: 0.2637254901960784]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:49<00:00,  1.09s/trial, best loss: 0.17647058823529416]\n",
      "Final Test Score is 0.8400297619047619\n",
      "best = {'a': 0, 'colsample_bytree': 0.9468496841939233, 'gamma': 19.83729315199124, 'learning_rate': 0.9090807452579128, 'max_depth': 1.358428579979779, 'n_estimators': 151.61832946821735, 'scale_pos_weight': 6.377353182581223}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.22trial/s, best loss: 0.28968253968253965]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.23765172735760967]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:07<00:00,  1.49trial/s, best loss: 0.2615546218487395]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.39173099044580567, 'gamma': 34.12505649711926, 'learning_rate': 0.5660739053862703, 'max_depth': 2.8539739077865685, 'n_estimators': 148.93648272541782, 'scale_pos_weight': 12.223474913566424}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.18849206349206346]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:30<00:00,  1.10trial/s, best loss: 0.23183940242763768]\n",
      "100%|████████████████████████████████████████████████| 100/100 [01:36<00:00,  1.04trial/s, best loss: 0.25968720821662]\n",
      "Final Test Score is 0.7269345238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.4413855567734921, 'gamma': 13.406169575759694, 'learning_rate': 0.7815524990142677, 'max_depth': 2.2115801763387024, 'n_estimators': 158.56628652492117, 'scale_pos_weight': 14.94915753148537}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:41<00:00,  1.01s/trial, best loss: 0.20238095238095236]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:39<00:00,  1.01trial/s, best loss: 0.14845938375350143]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:56<00:00,  1.16s/trial, best loss: 0.19808590102707746]\n",
      "Final Test Score is 0.7165178571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.3089112882083741, 'gamma': 11.793296530788155, 'learning_rate': 0.2049830810450155, 'max_depth': 7.907786068665514, 'n_estimators': 137.45559664992183, 'scale_pos_weight': 12.154897586029286}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:36<00:00,  1.04trial/s, best loss: 0.19642857142857137]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.20429505135387485]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.45trial/s, best loss: 0.22210550887021482]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.21973922189561568, 'gamma': 18.770293675100618, 'learning_rate': 0.28604823828297504, 'max_depth': 6.879614453951797, 'n_estimators': 100.23365487418205, 'scale_pos_weight': 10.43077893869042}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.29563492063492064]\n",
      "100%|█████████████████████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34trial/s, best loss: 0.5]\n",
      "100%|█████████████████████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.5]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.9591479384096161, 'gamma': 55.129616065908, 'learning_rate': 0.20147571253446916, 'max_depth': 6.452422031510618, 'n_estimators': 133.1080563541339, 'scale_pos_weight': 9.693795836011141}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.15674603174603172]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.25973389355742293]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:58<00:00,  1.18s/trial, best loss: 0.27156862745098037]\n",
      "Final Test Score is 0.7254464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.2865975918004906, 'gamma': 82.7728624590299, 'learning_rate': 0.6085343449018792, 'max_depth': 8.925784908722774, 'n_estimators': 148.72300999940296, 'scale_pos_weight': 6.873902020799582}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:46<00:00,  1.06s/trial, best loss: 0.20634920634920637]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:58<00:00,  1.19s/trial, best loss: 0.2378851540616246]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:06<00:00,  1.50trial/s, best loss: 0.2572362278244631]\n",
      "Final Test Score is 0.7529761904761905\n",
      "best = {'a': 0, 'colsample_bytree': 0.5021420573064197, 'gamma': 10.854930375590552, 'learning_rate': 0.5085943724168935, 'max_depth': 8.272738185545006, 'n_estimators': 194.50670502150243, 'scale_pos_weight': 9.606395029206652}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2083333333333333]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.22593370681605976]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.22994864612511667]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.2805265958620792, 'gamma': 19.928238384425185, 'learning_rate': 0.3971399776610788, 'max_depth': 2.504865678140343, 'n_estimators': 184.68696015593753, 'scale_pos_weight': 14.920010422126042}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.17063492063492058]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:24<00:00,  1.18trial/s, best loss: 0.1823062558356676]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:42<00:00,  1.03s/trial, best loss: 0.19614845938375347]\n",
      "Final Test Score is 0.7358630952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.581791055264606, 'gamma': 54.610546462287516, 'learning_rate': 0.9913533817282465, 'max_depth': 4.270609793983141, 'n_estimators': 119.23166665369797, 'scale_pos_weight': 12.60345948433555}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:40<00:00,  1.01s/trial, best loss: 0.1686507936507936]\n",
      "100%|███████████████████████████████████████████| 100/100 [1:00:43<00:00, 36.43s/trial, best loss: 0.13053221288515407]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:04<00:00,  1.55trial/s, best loss: 0.18436041083099905]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.2540540425630906, 'gamma': 20.632501954157757, 'learning_rate': 0.5647620855032082, 'max_depth': 3.39191971341252, 'n_estimators': 122.15002740023928, 'scale_pos_weight': 10.92546923638661}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.14682539682539683]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.31722689075630256]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.23380018674136324]\n",
      "Final Test Score is 0.7723214285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.49677498989194074, 'gamma': 36.94158801382813, 'learning_rate': 0.3399935706194601, 'max_depth': 4.339648931768571, 'n_estimators': 156.95149298899503, 'scale_pos_weight': 11.947216102273401}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.16666666666666666]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.24976657329598506]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:04<00:00,  1.54trial/s, best loss: 0.13870214752567692]\n",
      "Final Test Score is 0.7723214285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.6716408877431261, 'gamma': 30.64415293024041, 'learning_rate': 0.3223489856870946, 'max_depth': 3.4512826758104405, 'n_estimators': 199.8505664252413, 'scale_pos_weight': 14.933131076291831}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.1349206349206349]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.21402894491129784]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.21trial/s, best loss: 0.22586367880485528]\n",
      "Final Test Score is 0.7879464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.9995961077768142, 'gamma': 12.336838144974326, 'learning_rate': 0.6003141835883212, 'max_depth': 1.5167068209975065, 'n_estimators': 179.02822783249758, 'scale_pos_weight': 12.439469561817303}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.12698412698412698]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2474323062558357]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.28trial/s, best loss: 0.1527544351073763]\n",
      "Final Test Score is 0.6555059523809522\n",
      "best = {'a': 0, 'colsample_bytree': 0.7267805310520505, 'gamma': 53.173016169448616, 'learning_rate': 0.8350398484758397, 'max_depth': 4.591939813821527, 'n_estimators': 136.37121944518972, 'scale_pos_weight': 14.135444161484603}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.20634920634920625]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.41trial/s, best loss: 0.16253501400560222]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.2852474323062559]\n",
      "Final Test Score is 0.890625\n",
      "best = {'a': 0, 'colsample_bytree': 0.3320855888883695, 'gamma': 11.495142990257762, 'learning_rate': 0.9102197307056499, 'max_depth': 1.8372238010436057, 'n_estimators': 191.09091024027524, 'scale_pos_weight': 12.344886364746477}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.42857142857142855]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.2696078431372549]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.21220821661998138]\n",
      "Final Test Score is 0.8802083333333333\n",
      "best = {'a': 0, 'colsample_bytree': 0.6160429086439203, 'gamma': 11.183674079250736, 'learning_rate': 0.5290332956189825, 'max_depth': 9.284402430353689, 'n_estimators': 175.06935307907028, 'scale_pos_weight': 12.271097718756248}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.21825396825396826]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.25trial/s, best loss: 0.24985994397759106]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.13277310924369748]\n",
      "Final Test Score is 0.7410714285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.7671916177739271, 'gamma': 39.3164584600281, 'learning_rate': 0.37219950731358675, 'max_depth': 1.3246148406183011, 'n_estimators': 176.76082806783313, 'scale_pos_weight': 14.096973644974312}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.1805555555555555]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2774509803921569]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.2634920634920635]\n",
      "Final Test Score is 0.7633928571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.5192111660549792, 'gamma': 43.0355935292298, 'learning_rate': 0.9958113957074474, 'max_depth': 4.415570743201865, 'n_estimators': 147.14842881156576, 'scale_pos_weight': 11.443707642717719}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.2519841269841269]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.2160597572362278]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.23783846872082168]\n",
      "Final Test Score is 0.8191964285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.2430135762261464, 'gamma': 17.03315269066094, 'learning_rate': 0.5302402092275345, 'max_depth': 8.72276920861869, 'n_estimators': 190.31518163000703, 'scale_pos_weight': 9.892457476921205}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.2757936507936508]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43trial/s, best loss: 0.2101774042950513]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.20422502334267043]\n",
      "Final Test Score is 0.7671130952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.3984062391959654, 'gamma': 12.886008429126946, 'learning_rate': 0.2226991959929353, 'max_depth': 7.014770510944542, 'n_estimators': 147.58049992598905, 'scale_pos_weight': 7.63615116977031}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.2480158730158731]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:28<00:00,  1.13trial/s, best loss: 0.2734827264239029]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.2736694677871148]\n",
      "Final Test Score is 0.8697916666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.3613515827871645, 'gamma': 15.967874698891112, 'learning_rate': 0.4577690529189643, 'max_depth': 3.1023373688689717, 'n_estimators': 161.17081783219928, 'scale_pos_weight': 14.71983659703987}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.19444444444444445]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:24<00:00,  1.18trial/s, best loss: 0.17040149393090567]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:14<00:00,  1.35trial/s, best loss: 0.1542717086834734]\n",
      "Final Test Score is 0.6540178571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.7127633383333188, 'gamma': 128.93458945831898, 'learning_rate': 0.10066711207786583, 'max_depth': 6.872043602895445, 'n_estimators': 140.63882892454902, 'scale_pos_weight': 12.36353197128651}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.40trial/s, best loss: 0.20436507936507942]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.1525910364145658]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:22<00:00,  1.22trial/s, best loss: 0.22401960784313724]\n",
      "Final Test Score is 0.6294642857142857\n",
      "best = {'a': 0, 'colsample_bytree': 0.8386861061918895, 'gamma': 65.85472656286439, 'learning_rate': 0.03180695799698549, 'max_depth': 9.696801174823786, 'n_estimators': 162.94454383716572, 'scale_pos_weight': 11.659600502444919}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.31547619047619047]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2258169934640523]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.18020541549953317]\n",
      "Final Test Score is 0.9114583333333333\n",
      "best = {'a': 0, 'colsample_bytree': 0.6605381888250889, 'gamma': 69.31842450417484, 'learning_rate': 0.7290257567520191, 'max_depth': 9.834905627960449, 'n_estimators': 164.54333809005917, 'scale_pos_weight': 11.123258681658442}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.18650793650793648]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43trial/s, best loss: 0.31928104575163396]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.43trial/s, best loss: 0.21015406162464986]\n",
      "Final Test Score is 0.7983630952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.21655750275590663, 'gamma': 22.12030018635639, 'learning_rate': 0.20057850496459376, 'max_depth': 2.256161687253673, 'n_estimators': 197.03193562945495, 'scale_pos_weight': 6.057888069168089}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.18849206349206346]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.2578197945845005]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.27trial/s, best loss: 0.22773109243697476]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.6133641214005718, 'gamma': 40.80360362775972, 'learning_rate': 0.9996592585940625, 'max_depth': 9.885038117709193, 'n_estimators': 130.77392184232227, 'scale_pos_weight': 12.471450009940169}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.18055555555555555]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:17<00:00,  1.28trial/s, best loss: 0.136484593837535]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.1823996265172736]\n",
      "Final Test Score is 0.6919642857142857\n",
      "best = {'a': 0, 'colsample_bytree': 0.8736302676293575, 'gamma': 10.919894631865645, 'learning_rate': 0.061510225240814405, 'max_depth': 8.639819532483866, 'n_estimators': 143.34065016184312, 'scale_pos_weight': 11.369735577022707}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.22817460317460317]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.22012138188608776]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:05<00:00,  1.53trial/s, best loss: 0.13279645191409895]\n",
      "Final Test Score is 0.7358630952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.3367363000416151, 'gamma': 58.86197707109173, 'learning_rate': 0.7315880361431051, 'max_depth': 8.531599340386952, 'n_estimators': 159.12812011575326, 'scale_pos_weight': 9.47943241642651}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.2380952380952381]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.2418534080298785]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:05<00:00,  1.53trial/s, best loss: 0.2237628384687208]\n",
      "Final Test Score is 0.793154761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.3545136670607319, 'gamma': 27.97764296623117, 'learning_rate': 0.6509206421728799, 'max_depth': 4.685273016318853, 'n_estimators': 166.01538568437866, 'scale_pos_weight': 14.948582981489814}\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:02<00:00,  1.59trial/s, best loss: 0.119047619047619]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2218020541549954]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.29740896358543417]\n",
      "Final Test Score is 0.7879464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.9729740382471693, 'gamma': 27.557430507241378, 'learning_rate': 0.38283967207890784, 'max_depth': 4.996946623899062, 'n_estimators': 179.05522663479746, 'scale_pos_weight': 14.97171137878026}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43trial/s, best loss: 0.3253968253968254]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:06<00:00,  1.50trial/s, best loss: 0.1724789915966386]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.25364145658263304]\n",
      "Final Test Score is 0.7879464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.7902925019790481, 'gamma': 24.372176047162704, 'learning_rate': 0.7084990054792415, 'max_depth': 3.05458741770921, 'n_estimators': 128.24352113214061, 'scale_pos_weight': 9.715020106296668}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.27777777777777773]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.21001400560224084]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.24180672268907558]\n",
      "Final Test Score is 0.828125\n",
      "best = {'a': 0, 'colsample_bytree': 0.8327343799168938, 'gamma': 52.74541161958407, 'learning_rate': 0.8137837202182372, 'max_depth': 1.466896272595781, 'n_estimators': 196.914230090025, 'scale_pos_weight': 10.841948464484464}\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.242063492063492]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.29096638655462187]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:03<00:00,  1.59trial/s, best loss: 0.19810924369747898]\n",
      "Final Test Score is 0.6956845238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.566689121431845, 'gamma': 56.06364298252803, 'learning_rate': 0.4845931432115631, 'max_depth': 6.387605009759963, 'n_estimators': 196.44089861880437, 'scale_pos_weight': 11.685368371881262}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.22817460317460314]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.18788515406162465]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:27<00:00,  1.15trial/s, best loss: 0.18036881419234355]\n",
      "Final Test Score is 0.7514880952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.7296556352790573, 'gamma': 55.444013412475364, 'learning_rate': 0.5611251033159155, 'max_depth': 4.438086503424322, 'n_estimators': 169.72023580067807, 'scale_pos_weight': 13.407882523807304}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.1587301587301587]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.17616713352007465]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.23583099906629315]\n",
      "Final Test Score is 0.6502976190476191\n",
      "best = {'a': 0, 'colsample_bytree': 0.6939698223794115, 'gamma': 29.104278014310182, 'learning_rate': 0.30668879529211496, 'max_depth': 3.749678471056254, 'n_estimators': 165.63251373924544, 'scale_pos_weight': 11.994365734808659}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:23<00:00,  1.20trial/s, best loss: 0.2837301587301587]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.2593837535014005]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.15261437908496733]\n",
      "Final Test Score is 0.8385416666666666\n",
      "best = {'a': 0, 'colsample_bytree': 0.4723659597767966, 'gamma': 50.48323975129137, 'learning_rate': 0.26020132331683266, 'max_depth': 7.808994179074817, 'n_estimators': 175.4728882921471, 'scale_pos_weight': 13.462504851453378}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.2619047619047619]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2717553688141924]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:26<00:00,  1.16trial/s, best loss: 0.18986928104575163]\n",
      "Final Test Score is 0.828125\n",
      "best = {'a': 0, 'colsample_bytree': 0.22387584305571473, 'gamma': 14.295393983007443, 'learning_rate': 0.23458099950924774, 'max_depth': 7.489856629812103, 'n_estimators': 157.50501897996725, 'scale_pos_weight': 10.051075381136132}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.25396825396825395]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.1824463118580766]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.21020074696545288]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.7481585597660212, 'gamma': 34.17190461971745, 'learning_rate': 0.7172110371124454, 'max_depth': 9.9121153471976, 'n_estimators': 142.80674683047482, 'scale_pos_weight': 8.212878695024498}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.28571428571428575]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:21<00:00,  1.23trial/s, best loss: 0.3228057889822596]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.20427170868347347]\n",
      "Final Test Score is 0.715029761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.43088867474017, 'gamma': 98.5035684323774, 'learning_rate': 0.6521698792317852, 'max_depth': 4.44851138473275, 'n_estimators': 186.88630975253972, 'scale_pos_weight': 12.659403272903464}\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.251984126984127]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.2518207282913166]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.11094771241830063]\n",
      "Final Test Score is 0.7671130952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.2955776353117742, 'gamma': 41.09626666270186, 'learning_rate': 0.2559549266428252, 'max_depth': 7.2711015539573856, 'n_estimators': 123.22430115612347, 'scale_pos_weight': 14.447699429952998}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.31547619047619047]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:27<00:00,  1.15trial/s, best loss: 0.190219421101774]\n",
      "100%|███████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.255859010270775]\n",
      "Final Test Score is 0.8854166666666667\n",
      "best = {'a': 0, 'colsample_bytree': 0.9973317411638439, 'gamma': 11.20841814004526, 'learning_rate': 0.3402425803629435, 'max_depth': 8.390448060605857, 'n_estimators': 125.6724058517506, 'scale_pos_weight': 14.179124161881795}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.19642857142857137]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.30trial/s, best loss: 0.2578197945845005]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.25trial/s, best loss: 0.18844537815126053]\n",
      "Final Test Score is 0.7529761904761905\n",
      "best = {'a': 0, 'colsample_bytree': 0.33614395718810497, 'gamma': 11.064561960091638, 'learning_rate': 0.9325592785212141, 'max_depth': 3.5509764204444565, 'n_estimators': 186.9138021758691, 'scale_pos_weight': 9.967937918747772}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.21230158730158724]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.20623249299719892]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.47trial/s, best loss: 0.13865546218487393]\n",
      "Final Test Score is 0.7373511904761905\n",
      "best = {'a': 0, 'colsample_bytree': 0.44509791480160343, 'gamma': 32.11708910251487, 'learning_rate': 0.4224174689680119, 'max_depth': 4.380898191824212, 'n_estimators': 135.39161644286025, 'scale_pos_weight': 11.180913072089078}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.22420634920634916]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.45trial/s, best loss: 0.23008870214752572]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.3190242763772176]\n",
      "Final Test Score is 0.7358630952380951\n",
      "best = {'a': 0, 'colsample_bytree': 0.5792933562763111, 'gamma': 96.8679548456281, 'learning_rate': 0.09842433921820752, 'max_depth': 3.74376999359001, 'n_estimators': 130.27464252910934, 'scale_pos_weight': 14.395254094159764}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [07:51<00:00,  4.71s/trial, best loss: 0.24603174603174607]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:24<00:00,  1.18trial/s, best loss: 0.2718020541549953]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.2040849673202614]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.2637970982919025, 'gamma': 11.240451375729467, 'learning_rate': 0.4006278434810974, 'max_depth': 6.432521141412574, 'n_estimators': 186.17642795488538, 'scale_pos_weight': 6.1580093909671145}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:08<00:00,  1.47trial/s, best loss: 0.1884920634920635]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.2099673202614379]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.27759103641456584]\n",
      "Final Test Score is 0.8452380952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.8036775271492014, 'gamma': 11.763969083474265, 'learning_rate': 0.933511148449893, 'max_depth': 1.3263439632543688, 'n_estimators': 173.39085128985312, 'scale_pos_weight': 6.764027001954091}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.28trial/s, best loss: 0.33333333333333326]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.47trial/s, best loss: 0.23543417366946776]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:03<00:00,  1.58trial/s, best loss: 0.2499299719887956]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.6711756372732298, 'gamma': 38.41250830510582, 'learning_rate': 0.39656998360948154, 'max_depth': 5.085466849291613, 'n_estimators': 116.18844316696752, 'scale_pos_weight': 7.416530835195359}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.32trial/s, best loss: 0.21626984126984125]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.24180672268907563]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:06<00:00,  1.49trial/s, best loss: 0.21589635854341738]\n",
      "Final Test Score is 0.8854166666666667\n",
      "best = {'a': 0, 'colsample_bytree': 0.9511693706887525, 'gamma': 40.819146908728754, 'learning_rate': 0.38240297855383115, 'max_depth': 9.919911181387079, 'n_estimators': 158.88221772147614, 'scale_pos_weight': 14.359426934969802}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.41trial/s, best loss: 0.18650793650793654]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.28751167133520067]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.2657329598506069]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.5440401227988013, 'gamma': 48.663411516088104, 'learning_rate': 0.28108336598677697, 'max_depth': 5.882218792894887, 'n_estimators': 125.58235082028015, 'scale_pos_weight': 12.272326734507683}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.1726190476190476]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.28517740429505134]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.27166199813258635]\n",
      "Final Test Score is 0.8452380952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.20642489352632093, 'gamma': 33.40775436685486, 'learning_rate': 0.8316190095671874, 'max_depth': 8.962059149927127, 'n_estimators': 176.66700780869925, 'scale_pos_weight': 12.314269606838835}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:10<00:00,  1.42trial/s, best loss: 0.18650793650793648]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:03<00:00,  1.58trial/s, best loss: 0.20420168067226893]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.15067693744164332]\n",
      "Final Test Score is 0.7113095238095237\n",
      "best = {'a': 0, 'colsample_bytree': 0.46549138591301725, 'gamma': 10.492944068516586, 'learning_rate': 0.2695424632279336, 'max_depth': 5.42819908877159, 'n_estimators': 102.92731050397657, 'scale_pos_weight': 12.499820498414946}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2896825396825397]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.35trial/s, best loss: 0.17047152194211015]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.2657096171802054]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.619263149745858, 'gamma': 10.25493890755672, 'learning_rate': 0.1537323493729591, 'max_depth': 6.168243885246315, 'n_estimators': 107.89171635930958, 'scale_pos_weight': 14.97810180678137}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.1805555555555555]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.43trial/s, best loss: 0.32492997198879553]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:02<00:00,  1.60trial/s, best loss: 0.18424369747899152]\n",
      "Final Test Score is 0.7566964285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.3723824879785982, 'gamma': 13.977461194187818, 'learning_rate': 0.2958826763881626, 'max_depth': 1.375537588137296, 'n_estimators': 125.27381486284729, 'scale_pos_weight': 14.716038030378915}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.2599206349206349]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.25793650793650796]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:13<00:00,  1.37trial/s, best loss: 0.1902894491129785]\n",
      "Final Test Score is 0.84375\n",
      "best = {'a': 0, 'colsample_bytree': 0.5488930002347691, 'gamma': 31.400681641329626, 'learning_rate': 0.029206033481259802, 'max_depth': 8.545558076282909, 'n_estimators': 116.29248374543516, 'scale_pos_weight': 14.162058528048354}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.36904761904761907]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.39trial/s, best loss: 0.19612511671335198]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:11<00:00,  1.41trial/s, best loss: 0.26746031746031745]\n",
      "Final Test Score is 0.8125\n",
      "best = {'a': 0, 'colsample_bytree': 0.7172874383349811, 'gamma': 51.39631304054087, 'learning_rate': 0.6179554450553544, 'max_depth': 9.639130096996691, 'n_estimators': 167.0971094501746, 'scale_pos_weight': 14.345927484400214}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:20<00:00,  1.25trial/s, best loss: 0.29563492063492064]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.38trial/s, best loss: 0.17040149393090565]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:15<00:00,  1.33trial/s, best loss: 0.19635854341736692]\n",
      "Final Test Score is 0.715029761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.4041268978864486, 'gamma': 47.43129752179384, 'learning_rate': 0.22457226617138643, 'max_depth': 4.9241591618918115, 'n_estimators': 199.481748096543, 'scale_pos_weight': 11.993570747921837}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:05<00:00,  1.52trial/s, best loss: 0.1706349206349206]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:04<00:00,  1.54trial/s, best loss: 0.18811858076563956]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:12<00:00,  1.37trial/s, best loss: 0.17843137254901956]\n",
      "Final Test Score is 0.7477678571428572\n",
      "best = {'a': 0, 'colsample_bytree': 0.5336300160262506, 'gamma': 16.473991679353887, 'learning_rate': 0.32494560395619443, 'max_depth': 5.833897665331534, 'n_estimators': 110.30832507237949, 'scale_pos_weight': 13.719916565799393}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 100/100 [01:13<00:00,  1.36trial/s, best loss: 0.33134920634920634]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:05<00:00,  1.52trial/s, best loss: 0.2676237161531279]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:05<00:00,  1.52trial/s, best loss: 0.13851540616246494]\n",
      "Final Test Score is 0.875\n",
      "best = {'a': 0, 'colsample_bytree': 0.6360600744141591, 'gamma': 13.729722640459583, 'learning_rate': 0.4373269349275076, 'max_depth': 5.85218998744063, 'n_estimators': 127.68814564050044, 'scale_pos_weight': 12.109015732476148}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:08<00:00,  1.47trial/s, best loss: 0.2063492063492064]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.3053221288515406]\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:59<00:00,  1.67trial/s, best loss: 0.21211484593837537]\n",
      "Final Test Score is 0.8333333333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.6453930318293479, 'gamma': 10.31311708745031, 'learning_rate': 0.4148272639576834, 'max_depth': 1.9918630096728194, 'n_estimators': 100.17285378585045, 'scale_pos_weight': 9.733713164114654}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.2619047619047619]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.1246265172735761]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2181605975723623]\n",
      "Final Test Score is 0.8489583333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.2889485597605909, 'gamma': 21.519006995056547, 'learning_rate': 0.14971376078619444, 'max_depth': 7.283585133123492, 'n_estimators': 199.4668643482859, 'scale_pos_weight': 14.819806313617114}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:16<00:00,  1.31trial/s, best loss: 0.1845238095238095]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:07<00:00,  1.48trial/s, best loss: 0.17803454715219422]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:12<00:00,  1.39trial/s, best loss: 0.2257469654528478]\n",
      "Final Test Score is 0.6644345238095238\n",
      "best = {'a': 0, 'colsample_bytree': 0.8283579183075159, 'gamma': 94.99634387009307, 'learning_rate': 0.4074701025222004, 'max_depth': 7.746917781927062, 'n_estimators': 104.26959720181546, 'scale_pos_weight': 14.943157824805105}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:18<00:00,  1.27trial/s, best loss: 0.24801587301587294]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.16846405228758166]\n",
      "100%|██████████████████████████████████████████| 100/100 [6:34:39<00:00, 236.79s/trial, best loss: 0.24789915966386555]\n",
      "Final Test Score is 0.7879464285714286\n",
      "best = {'a': 0, 'colsample_bytree': 0.6531638206360655, 'gamma': 33.24722781989455, 'learning_rate': 0.6587613010876638, 'max_depth': 2.7488970359312144, 'n_estimators': 141.78627697724218, 'scale_pos_weight': 12.222384221865475}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:49<00:00,  1.09s/trial, best loss: 0.24404761904761904]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:06<00:00,  1.49trial/s, best loss: 0.15060690943043883]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:41<00:00,  1.02s/trial, best loss: 0.3591269841269842]\n",
      "Final Test Score is 0.7827380952380952\n",
      "best = {'a': 0, 'colsample_bytree': 0.9414621467762261, 'gamma': 39.76640795452185, 'learning_rate': 0.5546847222486226, 'max_depth': 2.559350018297651, 'n_estimators': 125.47999667573889, 'scale_pos_weight': 13.514041022741067}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:25<00:00,  1.17trial/s, best loss: 0.15079365079365079]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:09<00:00,  1.44trial/s, best loss: 0.21409897292250232]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.30trial/s, best loss: 0.3272175536881419]\n",
      "Final Test Score is 0.8645833333333334\n",
      "best = {'a': 0, 'colsample_bytree': 0.2029022527992757, 'gamma': 10.734206987864864, 'learning_rate': 0.17016766800405958, 'max_depth': 8.437290992311315, 'n_estimators': 117.35027310690683, 'scale_pos_weight': 13.090667305495572}\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:19<00:00,  1.26trial/s, best loss: 0.22817460317460317]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.46trial/s, best loss: 0.17035480859010269]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.45trial/s, best loss: 0.20387488328664802]\n",
      "Final Test Score is 0.7373511904761905\n",
      "best = {'a': 0, 'colsample_bytree': 0.7542763397431617, 'gamma': 35.81385015854306, 'learning_rate': 0.7769631445065328, 'max_depth': 9.854812397125565, 'n_estimators': 106.47086154357385, 'scale_pos_weight': 9.957637269772501}\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:17<00:00,  1.29trial/s, best loss: 0.1587301587301587]\n",
      "100%|██████████████████████████████████████████████| 100/100 [01:20<00:00,  1.24trial/s, best loss: 0.2697945845004669]\n",
      "100%|█████████████████████████████████████████████| 100/100 [01:08<00:00,  1.47trial/s, best loss: 0.29934640522875816]\n",
      "Final Test Score is 0.777529761904762\n",
      "best = {'a': 0, 'colsample_bytree': 0.5202335129116408, 'gamma': 15.166677359179083, 'learning_rate': 0.011949688030361432, 'max_depth': 2.308327528814419, 'n_estimators': 126.3932362060103, 'scale_pos_weight': 11.143613553520172}\n"
     ]
    }
   ],
   "source": [
    "### get out a list *primary_parameters* that has the parameters and aucs\n",
    "\n",
    "for i in range(100):\n",
    "    data = twenty_cutoff\n",
    "    do_nested_cv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cfadc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary pickle file \n",
    "f = open(\"cutoff analysis/twenty parameters.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(primary_parameters,f)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2653fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_parameters = pd.read_pickle(r'cutoff analysis/twenty parameters.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08de7ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take these parameters to R\n",
    "param_top_ten = sorted(twenty_parameters, key = lambda x: x[1])[-10:]\n",
    "params = [a[0] for a in param_top_ten]\n",
    "param_df = pd.DataFrame(params).drop(columns = ['a'])\n",
    "param_df.to_csv('cutoff analysis/twenty top 10 parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d59b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GARLIC~1\\AppData\\Local\\Temp/ipykernel_9272/1850536246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Train the model with train data sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         )\n\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m# Copy to serialise and unserialise booster to reset state and free\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m# training memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mcopied\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m         \"\"\"\n\u001b[1;32m-> 1348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__copy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__copy__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__copy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m   1336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__deepcopy__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[1;34m'''Return a copy of booster.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, cache, model_file)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             _check_call(\n\u001b[1;32m-> 1216\u001b[1;33m                 _LIB.XGBoosterUnserializeFromBuffer(self.handle, ptr, length))\n\u001b[0m\u001b[0;32m   1217\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSTRING_TYPES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####\n",
    "#FOR EACH OF THE 10 BEST PERFORMING PARAMETERS IN ORIGINAL_MODELS, DO EVALUATIONS ON 10 RANDOM STATE SPLITS\n",
    "####\n",
    "\n",
    "param_dict = param_top_ten\n",
    "auc_list = []\n",
    "data = twenty_cutoff\n",
    "\n",
    "for x in range(10):\n",
    "    params = {'max_depth': int(param_dict[x][0]['max_depth']), 'gamma': param_dict[x][0]['gamma'],\n",
    "                              'learning_rate': param_dict[x][0]['learning_rate'], 'n_estimators': int(param_dict[x][0]['n_estimators']),\n",
    "                              'scale_pos_weight': int(param_dict[x][0]['scale_pos_weight']), 'colsample_bytree': param_dict[x][0]['colsample_bytree']}\n",
    "    X = data.iloc[:,:-1] # Feature matrix in pd.DataFrame format\n",
    "    y = data.iloc[:,-1] # Target vector in pd.Series format\n",
    "    \n",
    "    for q in range(10):\n",
    "\n",
    "        # Making train and test sets for both X and y\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "        # Instantiate an XGBoost object with hyperparameters\n",
    "        xgb_clf = xgb.XGBClassifier(**params,\n",
    "                                    objective='binary:logistic', booster='gbtree', \n",
    "                                    n_jobs=2, eval_metric = 'logloss', use_label_encoder=False)\n",
    "\n",
    "        # Train the model with train data sets\n",
    "        xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "        prob = np.array(pd.DataFrame(xgb_clf.predict_proba(X_test))[1])\n",
    "        for x in range(len(prob)):\n",
    "            if prob[x] > np.mean(np.array(pd.DataFrame(xgb_clf.predict_proba(X_test))[1])):\n",
    "                prob[x] = 1\n",
    "            else:\n",
    "                prob[x] = 0\n",
    "\n",
    "        y_pred = prob\n",
    "        y_true = y_test # True values\n",
    "\n",
    "#         print(\"Accuracy: \", np.round(accuracy_score(y_true, y_pred), 3))\n",
    "\n",
    "        auc_list.append(roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "        #less ugly step curve\n",
    "#         plot_roc_curve(xgb_clf, X_test, y_test, color='lightgrey', ax=ax)\n",
    "\n",
    "# ax.get_legend().remove()\n",
    "# print(auc_list)\n",
    "print('median AUC: ' + str(np.median(auc_list)))\n",
    "print('mean AUC: ' + str(np.mean(auc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77a9298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard error 0.007871751025696757\n",
      "std 0.07871751025696758\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import sem\n",
    "print(\"standard error\", sem(auc_list))\n",
    "print(\"std\", np.std(auc_list, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1c3045f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFuCAYAAABQqakCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaL0lEQVR4nO3dfbRddX3n8fenCVRBWrBEBCSJdRgUWYJ4RR1UUEcnZHwepyX1uWrE0Vm62mml1qV2zZpVZ3WpUwdHjMr4MIoPVSydRgSZFnRGxYhBgoBEJBDDkqBrxKcRg9/5Y+/I9fbc5CT37vPLvff9Wmuvux9+e5/v2bn5ZOd39v6dVBWSpDZ+o3UBkrSUGcKS1JAhLEkNGcKS1JAhLEkNLW9dwHxas2ZNXXLJJa3LkKTpsqeNi+pK+M4772xdgiTtk0UVwpK00BjCktSQISxJDRnCktSQISxJDRnCktSQISxJDRnCktSQISxJDRnCktSQISxJDQ0WwkmOS/IPSa5Pcl2S1/br75/ksiQ39T+PmGX/NUluTLI1yblD1SlJLQ15JbwL+OOqehjwWODVSU4EzgUur6rjgcv75V+TZBnwLuAs4ERgXb+vJC0qg4VwVd1eVVf38z8CrgeOBZ4FfLBv9kHg2SN2Pw3YWlU3V9XdwMf6/SRpUZlIn3CS1cAjga8AR1XV7dAFNfCAEbscC9w2bXl7v27Usdcn2ZRk086dO+e1bmmpWblqNUnmPK1ctbr1W1kwBh/UPcn9gE8Br6uqu5I9jm/8q91GrKtRDatqA7ABYGpqamQbSeO57dZtXLFt7uNyn7HqyHmoZmkY9Eo4yUF0AfyRqvp0v/p7SY7utx8N3DFi1+3AcdOWHwTsGLJWSWphyLsjArwfuL6q3j5t08XAi/v5FwN/O2L3rwLHJ3lwkoOBs/v9JGlRGfJK+HTghcCTk2zup7XAW4GnJrkJeGq/TJJjkmwEqKpdwGuAz9F9oPeJqrpuwFolqYnB+oSr6ovM/gV3TxnRfgewdtryRmDjMNVJ0oHBJ+YkqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqaHlQx04yQXA04E7quqkft3HgRP6JocD/7eqThmx7y3Aj4B7gF1VNTVUnZLU0mAhDHwAOA/40O4VVfX7u+eTvA344R72f1JV3TlYdZJ0ABgshKvqyiSrR21LEuD3gCcP9fqStBC06hN+AvC9qrpplu0FXJrka0nW7+lASdYn2ZRk086dO+e9UEkaUqsQXgdcuIftp1fVqcBZwKuTPHG2hlW1oaqmqmpqxYoV812nJA1q4iGcZDnwXODjs7Wpqh39zzuAi4DTJlOdJE1WiyvhfwncUFXbR21McmiSw3bPA08DtkywPkmamMFCOMmFwJeAE5JsT/KyftPZzOiKSHJMko394lHAF5NcA1wF/H1VXTJUnZLU0pB3R6ybZf1LRqzbAazt528GTh6qLkk6kPjEnCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1ZAhLUkOGsCQ1NFgIJ7kgyR1Jtkxb95Yk302yuZ/WzrLvmiQ3Jtma5NyhapSk1oa8Ev4AsGbE+ndU1Sn9tHHmxiTLgHcBZwEnAuuSnDhgnZLUzGAhXFVXAj/Yj11PA7ZW1c1VdTfwMeBZ81qcJB0gWvQJvybJN/ruiiNGbD8WuG3a8vZ+3UhJ1ifZlGTTzp0757tWSRrUpEP43cBDgFOA24G3jWiTEetqtgNW1YaqmqqqqRUrVsxLkZI0KRMN4ar6XlXdU1W/BN5L1/Uw03bguGnLDwJ2TKI+SZq0iYZwkqOnLT4H2DKi2VeB45M8OMnBwNnAxZOoT5ImbflQB05yIXAmcGSS7cCbgTOTnELXvXAL8Mq+7THA+6pqbVXtSvIa4HPAMuCCqrpuqDolqaXBQriq1o1Y/f5Z2u4A1k5b3gj8k9vXJGmx8Yk5SWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJakhgxhSWrIEJYWgZWrVpNkzpMmb3nrAiTN3W23buOKbXfO+ThnrDpyHqrRvvBKWJIaMoQlqaHBQjjJBUnuSLJl2rq/SnJDkm8kuSjJ4bPse0uSa5NsTrJpqBolqbUhr4Q/AKyZse4y4KSqegTwLeDP9rD/k6rqlKqaGqg+SWpusBCuqiuBH8xYd2lV7eoXvww8aKjXl6SFoGWf8B8Cn51lWwGXJvlakvV7OkiS9Uk2Jdm0c+fOeS9SkobUJIST/DmwC/jILE1Or6pTgbOAVyd54mzHqqoNVTVVVVMrVqwYoFpJGs7EQzjJi4GnA8+vqhrVpqp29D/vAC4CTptchZI0ORMN4SRrgNcDz6yqn87S5tAkh+2eB54GbBnVVpIWuiFvUbsQ+BJwQpLtSV4GnAccBlzW3352ft/2mCQb+12PAr6Y5BrgKuDvq+qSoeqUpJYGe2y5qtaNWP3+WdruANb28zcDJw9VlyQdSHxiTpIaMoQlqaGxQjjJSUMXIklL0bhXwucnuSrJv5ttvAdJ0r4bK4Sr6vHA84HjgE1JPprkqYNWJklLwNh9wlV1E/BGuvt8zwDe2Y+I9tyhipOkxW7cPuFHJHkHcD3wZOAZVfWwfv4dA9YnSYvauPcJnwe8F3hDVf1s98qq2pHkjYNUJklLwLghvBb4WVXdA5DkN4D7VNVPq+rDg1UnSYvcuH3CnwfuO235kH6dJGkOxg3h+1TVj3cv9POHDFOSJC0d44bwT5KcunshyaOAn+2hvSRpDOP2Cb8O+GSSHf3y0cDvD1KRJC0hY4VwVX01yUOBE4AAN1TVLwatTJKWgH0ZyvLRwOp+n0cmoao+NEhVkrREjBXCST4MPATYDNzTry7AEJakORj3SngKOHG274STJO2fce+O2AI8cMhCpKVo5arVJJnzpIVr3CvhI4FvJrkK+PnulVX1zEGqkpaI227dxhXb7pzzcc5YdeQ8VKMWxg3htwxZhCQtVePeonZFklXA8VX1+SSHAMuGLU2SFr9xh7J8BfA3wHv6VccCnxmoJklaMsb9YO7VwOnAXfCrAd4fMFRRkrRUjBvCP6+qu3cvJFlOd5+wJGkOxg3hK5K8Abhv/91ynwT+briyJGlpGDeEzwV2AtcCrwQ20n3fnCRpDsa9O+KXdF9v9N5hy5GkpWXcsSO+w4g+4Kr63XmvSJKWkH0ZO2K3+wD/Frj//JcjSUvLWH3CVfX9adN3q+q/0H3dvSRpDsZ9WOPUadNUknOAw/ayzwVJ7kiyZdq6+ye5LMlN/c8jZtl3TZIbk2xNcu4+vSNJWkDGvTvibdOmvwQeBfzeXvb5ALBmxrpzgcur6njg8n751yRZBrwLOAs4EViX5MQx65SkBWXcuyOetK8Hrqork6yesfpZwJn9/AeBfwReP6PNacDWqroZIMnH+v2+ua81SNKBbty7I/5oT9ur6u1jvt5RVXV7v8/tSUY9+nwscNu05e3AY/ZQ23pgPcDKlSvHLEML0cpVq7nt1m1zPs5xK1dx67Zb5l6QZrVs+UHzMs7xUviz2pe7Ix4NXNwvPwO4kl8Py/ky6k9u1kekq2oDsAFgamrKR6kXMcfeXTju2fUL/6zGtC+Dup9aVT8CSPIW4JNV9fJ9fL3vJTm6vwo+GrhjRJvtwHHTlh8E7NjH15GkBWHcD+ZWAndPW76b7puX99XFwIv7+RcDfzuizVeB45M8OMnBwNncewUuSYvKuFfCHwauSnIRXdfAc9jLNy0nuZDuQ7gjk2wH3gy8FfhEkpcBt9I99EGSY4D3VdXaqtqV5DXA5+gGjr+gqq7b53cmSQvAuHdH/KcknwWe0K96aVV9fS/7rJtl01NGtN0BrJ22vJFukCBJWtTG7Y4AOAS4q6r+Gtie5MED1SRJS8a4T8y9me5+3j/rVx0E/I+hipKkpWLcK+HnAM8EfgK/6j7Y42PLkqS9GzeE766qor9fN8mhw5UkSUvHuCH8iSTvAQ7vv3n58zjAuyTN2V7vjkj37OHHgYfSfdvyCcCbquqygWuTpEVvryFcVZXkM1X1KMDglaR5NG53xJeTPHrQSiRpCRr3ibknAeckuYXuDonQXSQ/YqjCJGkp2GMIJ1lZVbfSDbAuSRM1H0NiHujDYe7tSvgzdKOnbUvyqar6NxOoSZKA+RkS80AfDnNvfcLT/wny6+0laZ7tLYRrlnlJ0jzYW3fEyUnuorsivm8/D/d+MPdbg1YnSYvcHkO4qpZNqhBJWor2ZShLSdI8M4QlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoSl/bBy1WqSzHmSxh3UXdI0t926bc5DLMKBP8yihueVsCQ1ZAhLUkOGsCQ1NPEQTnJCks3TpruSvG5GmzOT/HBamzdNuk5JmoSJfzBXVTcCpwAkWQZ8F7hoRNMvVNXTJ1iaJE1c6+6IpwDfrqptjeuQpCZah/DZwIWzbHtckmuSfDbJw2c7QJL1STYl2bRz585hqpSkgTQL4SQHA88EPjli89XAqqo6GfivwGdmO05VbaiqqaqaWrFixSC1StJQWl4JnwVcXVXfm7mhqu6qqh/38xuBg5J4V7ukRadlCK9jlq6IJA9M/0xnktPo6vz+BGuTpIlo8thykkOApwKvnLbuHICqOh94HvCqJLuAnwFnV1W1qFWShtQkhKvqp8DvzFh3/rT584DzJl2XJE1a67sjJGlJM4QlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaMoQlqSFDWJIaahLCSW5Jcm2SzUk2jdieJO9MsjXJN5Kc2qJOSRra8oav/aSqunOWbWcBx/fTY4B39z8laVE5ULsjngV8qDpfBg5PcnTroiRpvrUK4QIuTfK1JOtHbD8WuG3a8vZ+3T+RZH2STUk27dy5c4BSNVcrV60myZwnaX8sW37QvPz+rVy1epD6WnVHnF5VO5I8ALgsyQ1VdeW07aP+xtWoA1XVBmADwNTU1Mg2auu2W7dxxbbZep7Gd8aqI+ehGi019+z6xQH9+9fkSriqdvQ/7wAuAk6b0WQ7cNy05QcBOyZTnSRNzsRDOMmhSQ7bPQ88Ddgyo9nFwIv6uyQeC/ywqm6fcKmSNLgW3RFHARf1fXzLgY9W1SVJzgGoqvOBjcBaYCvwU+ClDeqUpMFNPISr6mbg5BHrz582X8CrJ1mXJLVwoN6iJklLgiEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLU0PLWBUiTtmz5QSRpXYYEGMJagu7Z9Quu2HbnnI5xxqoj56kaLXV2R0hSQ4awJDU08RBOclySf0hyfZLrkrx2RJszk/wwyeZ+etOk65SkSWjRJ7wL+OOqujrJYcDXklxWVd+c0e4LVfX0BvVJ0sRM/Eq4qm6vqqv7+R8B1wPHTroOSToQNO0TTrIaeCTwlRGbH5fkmiSfTfLwyVYmSZPR7Ba1JPcDPgW8rqrumrH5amBVVf04yVrgM8DxsxxnPbAeYOXKlcMVLEkDaHIlnOQgugD+SFV9eub2qrqrqn7cz28EDkoy8sbMqtpQVVNVNbVixYpB65ak+dbi7ogA7weur6q3z9LmgX07kpxGV+f3J1elJE1Gi+6I04EXAtcm2dyvewOwEqCqzgeeB7wqyS7gZ8DZVVUNapWkQU08hKvqi8AeH9yvqvOA8yZTkSS14xNzktSQISxJDS35EF65ajVJ5jytXLW69Vv5lcX4nqTFaskPZXnbrdvmPKwhHFhDGy7G9yQtVkv+SliSWjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGjKEJakhQ1iSGlryo6jNl2XLD6L/Wrw5Ofg378PdP/9/81CRpIXAEJ4n9+z6xbwNHznX4zgEpbRw2B0hSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ0ZwpLUkCEsSQ01CeEka5LcmGRrknNHbE+Sd/bbv5Hk1BZ1StLQJh7CSZYB7wLOAk4E1iU5cUazs4Dj+2k98O6JFilJE9LiSvg0YGtV3VxVdwMfA541o82zgA9V58vA4UmOnnShkjS0VNVkXzB5HrCmql7eL78QeExVvWZam/8JvLWqvtgvXw68vqo2jTjeerqrZYATgBunbT4SmPv4kvPDWkazltGsZbSFWMudVbVmto0txhMeNfL5zH8JxmnTrazaAGwY+ULJpqqa2rfyhmEto1nLaNYy2mKspUV3xHbguGnLDwJ27EcbSVrwWoTwV4Hjkzw4ycHA2cDFM9pcDLyov0viscAPq+r2SRcqSUObeHdEVe1K8hrgc8Ay4IKqui7JOf3284GNwFpgK/BT4KX7+XIjuykasZbRrGU0axlt0dUy8Q/mJEn38ok5SWrIEJakhhZsCO/t0ee+zZlJNie5LskV+7LvBGu5Jcm1/bZ/ch/0fNeS5E/619qcZEuSe5Lcf9z3McFaJn1efjvJ3yW5pv8zeum4+06wjkmfkyOSXNQPHXBVkpPG3XfCtcz3ebkgyR1JtsyyPZllWIX9Oi9VteAmug/0vg38LnAwcA1w4ow2hwPfBFb2yw8Yd99J1dLP3wIcOanzMqP9M4D/1eq8zFZLi/MCvAH4z/38CuAHfdt5Oy9zqaPROfkr4M39/EOByxv+HRpZy3yfl/54TwROBbbMsn0t8Fm65xkeC3xlLudloV4Jj/Po8x8An66qWwGq6o592HdStcy3fX1v64AL93PfIWuZb+PUUsBhSQLcjy78do257yTqmG/j1HIicDlAVd0ArE5y1Jj7TqqWeVdVV9Kd99nMNqzCfp2XhRrCxwK3TVve3q+b7p8DRyT5xyRfS/Kifdh3UrVA95fu0n79euZm7PeW5BBgDfCpfd13ArXA5M/LecDD6B4KuhZ4bVX9csx9J1EHTP6cXAM8FyDJacAqugenWvyuzFYLzO95Gcds9e7XeWnx2PJ8GOex5uXAo4CnAPcFvpTky2PuO5FaqupbwOlVtSPJA4DLktzQ/0s8VC27PQP431W1+1/8Fudltlpg8uflXwGbgScDD+lf8wtj7jt4HVV1F5M/J28F/jrJZrp/EL5Od1Xe4ndltlpgfs/LOGard7/Oy0K9Eh730edLquonVXUncCVw8pj7TqoWqmpH//MO4CK6/9IMWctuZ/Pr//1vcV5mq6XFeXkpXZdRVdVW4Dt0fY/zeV7mUsfEz0lV3VVVL62qU4AX0fVRf2fM9zGpWub7vMyl3v07L/PVmT3Jie7K8mbgwdzbAf7wGW0eRteHtBw4BNgCnDTOvhOs5VDgsL7NocD/oRthbrBa+na/Tdfndei+7juhWiZ+XujGrH5LP38U8F26UbLm7bzMsY4W5+Rw7v1Q8BV0/aBNflf2UMu8npdpr7ea2T+Y+9f8+gdzV83lvMyp0JYT3SeU36L7NPLP+3XnAOdMa/MndHclbAFet6d9W9RC9ynqNf103QRreQnwsXH2bVFLi/MCHANcSvdf3S3AC4Y4L/tbR6Nz8jjgJuAG4NPAEa1+V2arZaDzciFwO/ALuqvbl82oJXRfTPHt/s9pai7nxceWJamhhdonLEmLgiEsSQ0ZwpLUkCEsSQ0ZwpLUkCGsBSnJc5JUkodOW3dmum/qnt7uA+m+4ZskByV5a5Kb0o3adlWSs0Yc++lJvt6PZPbNJK8c/h1pqVqojy1L64Av0j1t95Yx9/mPwNHASVX1834AmDOmN0hyEN3X1pxWVduT/Cbdjfv7rR+MJ3XvGBDSr3glrAUnyf2A0+luoj97zH0OoXvS6t9X1c8Bqup7VfWJGU0Po7s4+X7f5udVdWN/jKP6MW2v6ad/0a//o/7KekuS1/XrVie5Psl/A64Gjks3fvJX+zFo/2KOp0GLhCGshejZdGNxfAv4wfRBtffgnwG3VjcQzqyqG0ToYmBbkguTPD/J7r8n7wSuqKqT6cabvS7Jo+jGe3gM3SOsr0jyyL79CXSP1z6ynz+eblyDU4BHJXni2O9Yi5YhrIVoHd1YrfQ/1/Xzsz3+uU+PhVbVy+lGvLsK+A/ABf2mJ9ON7UBV3VNVPwQeD1xU3eBMP6Z7pPYJfftt1Y03C/C0fvo63ZXxQ+lCWUucfcJaUJL8Dl0YnpSk6L7NoJL8KV0XwhEzdrk/cCewFViZ5LCq+tHeXqeqrgWuTfJhutG6XjJbSXs4zE9mtPvLqnrP3l5bS4tXwlponkf3X/xVVbW6qo6jC8nH0w3wckyShwEkWUU3ZOjmqvop8H7gnUkO7rcfneQF0w+e5H5Jzpy26hRgWz9/OfCqvt2yJL9FNyzps5MckuRQ4DnAF0bU/TngD/v+bJIc249/qyXOENZCs45uzNjpPgX8Qf+B2wuA/94P/v03wMv7bgOANwI7gW+m+xLHz/TL0wX40/7LGjcDf8G9V8GvBZ6U5Frga3TDFF4NfICu6+IrwPuq6uszi66qS4GP0g3of21f22H78f61yDiKmiQ15JWwJDVkCEtSQ4awJDVkCEtSQ4awJDVkCEtSQ4awJDX0/wHIUHSVo7VdjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from the 10 best models, 100 aucs in a histogram\n",
    "sns.displot(auc_list, bins = 15, color='lightblue')\n",
    "plt.xlabel('AUC Score')\n",
    "plt.ylabel('Frequency')\n",
    "# plt.title('Nested Cross Validation AUC Scores', fontsize = 15)\n",
    "\n",
    "#median = 0.882\n",
    "#mean = 0.880\n",
    "plt.savefig('cutoff analysis/twenty auc scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "025925ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 iterations using random state and 10 best params\n",
    "#for each best param, do 10 predictions using random states\n",
    "\n",
    "data = twenty_cutoff\n",
    "param_dict = sorted(param_top_ten, key = lambda x: x[1])[-10:]\n",
    "prediction_matrix = pd.DataFrame(original_clean.reset_index()['species'])  \n",
    "models_list_proven = []\n",
    "\n",
    "for x in range(10):\n",
    "    params = {'max_depth': int(param_dict[x][0]['max_depth']), 'gamma': param_dict[x][0]['gamma'],\n",
    "                              'learning_rate': param_dict[x][0]['learning_rate'], 'n_estimators': int(param_dict[x][0]['n_estimators']),\n",
    "                              'scale_pos_weight': int(param_dict[x][0]['scale_pos_weight']), 'colsample_bytree': param_dict[x][0]['colsample_bytree']}\n",
    "    \n",
    "    for u in range(10):\n",
    "        X, y = data.iloc[:,:-1], data.iloc[:,-1]\n",
    "        #stratify to make sure the 1s are distributed evenly\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "        \n",
    "        model = XGBClassifier(**params, booster='gbtree', objective='binary:logistic', eval_metric = 'logloss', use_label_encoder=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        models_list_proven.append(model)\n",
    "\n",
    "        #predictions in an array\n",
    "        y = model.predict_proba(X)\n",
    "\n",
    "        #match prediction to the species for this split\n",
    "        probability_table = X.reset_index() #get the species in the test set\n",
    "        probability_table['probability'] = pd.DataFrame(pd.DataFrame(y)[1]) #get the probabilities\n",
    "        probability_table = probability_table[['species', 'probability']]\n",
    "        #put the prediction in the big df\n",
    "        for a in range(len(prediction_matrix)):\n",
    "            for b in range(len(probability_table)):\n",
    "                if prediction_matrix.loc[a, 'species'] == probability_table.loc[b, 'species']:\n",
    "                    prediction_matrix.loc[a, str(x) + '.' + str(u)] = probability_table.loc[b, 'probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa9872d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>probability</th>\n",
       "      <th>std</th>\n",
       "      <th>percentile</th>\n",
       "      <th>potential/proven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bichromomyia flaviscutellata</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nyssomyia intermedia</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.998</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Psychodopygus davisi</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.996</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nyssomyia whitmani</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.994</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Psathyromyia (Psathyromyia) shannoni</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.992</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Brumptomyia bragai</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Evandromyia (Evandromyia) wilsoni</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Evandromyia (Barrettomyia) costalimai</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Evandromyia (Barrettomyia) callipyga</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Brumptomyia mangabeirai</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   species  probability    std  percentile  \\\n",
       "0             Bichromomyia flaviscutellata        0.941  0.083       1.000   \n",
       "1                     Nyssomyia intermedia        0.910  0.083       0.998   \n",
       "2                     Psychodopygus davisi        0.909  0.085       0.996   \n",
       "3                       Nyssomyia whitmani        0.904  0.073       0.994   \n",
       "4     Psathyromyia (Psathyromyia) shannoni        0.903  0.109       0.992   \n",
       "..                                     ...          ...    ...         ...   \n",
       "507                     Brumptomyia bragai        0.036  0.031       0.012   \n",
       "508      Evandromyia (Evandromyia) wilsoni        0.036  0.032       0.006   \n",
       "509  Evandromyia (Barrettomyia) costalimai        0.036  0.032       0.006   \n",
       "510   Evandromyia (Barrettomyia) callipyga        0.036  0.032       0.006   \n",
       "511                Brumptomyia mangabeirai        0.034  0.031       0.002   \n",
       "\n",
       "     potential/proven  \n",
       "0                 2.0  \n",
       "1                 2.0  \n",
       "2                 2.0  \n",
       "3                 2.0  \n",
       "4                 2.0  \n",
       "..                ...  \n",
       "507               0.0  \n",
       "508               0.0  \n",
       "509               0.0  \n",
       "510               0.0  \n",
       "511               0.0  \n",
       "\n",
       "[512 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a prediction table with the median probability and percentile for each species\n",
    "prediction_matrix['std'] = pd.DataFrame(prediction_matrix.std(axis=1))\n",
    "prediction_matrix['probability'] = pd.DataFrame(prediction_matrix.median(axis=1))\n",
    "top_predictions = prediction_matrix\n",
    "top_predictions['percentile'] = top_predictions.probability.rank(pct=True)\n",
    "\n",
    "#these are the sandflies where the probability its a vector is greater than 0.5\n",
    "#top_predictions = top_predictions[top_predictions['probability'] >= 0.5].reset_index(drop=True)\n",
    "\n",
    "#get the important stats only\n",
    "top_predictions = top_predictions[['species', 'probability','std', 'percentile']].reset_index(drop=True)\n",
    "\n",
    "#add real labels\n",
    "top_predictions = getstatus(top_predictions, 'leish')\n",
    "top_predictions = top_predictions.fillna(0)\n",
    "\n",
    "#sort by probability\n",
    "final_predictions = top_predictions.sort_values(by ='probability', ascending=False).reset_index(drop=True)\n",
    "final_predictions = final_predictions.round(3)\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2dda1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final predictions\n",
    "final_predictions.to_csv(\"cutoff analysis/twenty all predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90f591c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>probability</th>\n",
       "      <th>std</th>\n",
       "      <th>percentile</th>\n",
       "      <th>potential/proven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Nyssomyia antunesi</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.967</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Psychodopygus amazonensis</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Psychodopygus claustrei</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pintomyia (Pintomyia) pessoai</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Psychodopygus guyanensis</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Psathyromyia (Psathyromyia) bigeniculata</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Trichophoromyia auraensis</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sciopemyia sordellii</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.924</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Psychodopygus chagasi</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Evandromyia (Evandromyia) infraspinosa</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pressatia choti</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Trichophoromyia castanheirai</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Micropygomyia (Sauromyia) venezuelensis</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Psathyromyia (Psathyromyia) lanei</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     species  probability    std  percentile  \\\n",
       "17                        Nyssomyia antunesi        0.849  0.089       0.967   \n",
       "18                 Psychodopygus amazonensis        0.837  0.116       0.965   \n",
       "22                   Psychodopygus claustrei        0.797  0.156       0.957   \n",
       "27             Pintomyia (Pintomyia) pessoai        0.769  0.198       0.947   \n",
       "29                  Psychodopygus guyanensis        0.755  0.186       0.943   \n",
       "32  Psathyromyia (Psathyromyia) bigeniculata        0.741  0.164       0.938   \n",
       "37                 Trichophoromyia auraensis        0.725  0.159       0.928   \n",
       "39                      Sciopemyia sordellii        0.615  0.238       0.924   \n",
       "41                     Psychodopygus chagasi        0.563  0.207       0.920   \n",
       "42    Evandromyia (Evandromyia) infraspinosa        0.552  0.214       0.918   \n",
       "43                           Pressatia choti        0.530  0.222       0.916   \n",
       "44              Trichophoromyia castanheirai        0.526  0.204       0.914   \n",
       "46   Micropygomyia (Sauromyia) venezuelensis        0.513  0.219       0.910   \n",
       "47         Psathyromyia (Psathyromyia) lanei        0.500  0.211       0.908   \n",
       "\n",
       "    potential/proven  \n",
       "17               1.0  \n",
       "18               1.0  \n",
       "22               0.0  \n",
       "27               1.0  \n",
       "29               0.0  \n",
       "32               0.0  \n",
       "37               1.0  \n",
       "39               1.0  \n",
       "41               0.0  \n",
       "42               0.0  \n",
       "43               0.0  \n",
       "44               0.0  \n",
       "46               0.0  \n",
       "47               0.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get new predicted\n",
    "new_predicted = final_predictions[final_predictions['potential/proven']!=2]\n",
    "new_predicted = new_predicted[new_predicted['probability'] >= 0.5]\n",
    "new_predicted\n",
    "#how many non vectors did it predict to be a vector?\n",
    "# len(d[d['probability'] >= 0.5]) = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f651692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the csv\n",
    "new_predicted.to_csv(\"cutoff analysis/twenty new predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c890876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes in modelslist created in the predtable function, returns dataframe of variables and importances\n",
    "def var_impt(list_of_models):\n",
    "\n",
    "    impt_matrix = pd.DataFrame(list_of_models[0].feature_importances_, twenty_cutoff.columns[0:77])\n",
    "    for x in range(1, len(list_of_models)):\n",
    "        var_array = pd.DataFrame(list_of_models[x].feature_importances_, twenty_cutoff.columns[0:77])\n",
    "        impt_matrix[x] = var_array[0]\n",
    "        \n",
    "    var_impt_df = pd.DataFrame()\n",
    "    var_impt_df['feature'] = twenty_cutoff.columns[0:77]\n",
    "    var_impt_df = var_impt_df.set_index('feature')\n",
    "    for var in twenty_cutoff.columns[0:77]:\n",
    "        mean = impt_matrix.loc[var].mean()\n",
    "        var_impt_df.loc[var, 'importance'] = mean\n",
    "        std = impt_matrix.loc[var].std()\n",
    "        var_impt_df.loc[var, 'std'] = std\n",
    "\n",
    "    var_impt_df = var_impt_df.reset_index()\n",
    "    \n",
    "    return impt_matrix, var_impt_df.round(3).sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f518fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_impt_conf = var_impt(models_list_proven)[1]\n",
    "var_impt_conf['lower'] = var_impt_conf['importance'] - 1.96 * var_impt_conf['std'] / 10\n",
    "var_impt_conf['higher'] = var_impt_conf['importance'] + 1.96 * var_impt_conf['std'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "391229c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_impt_conf.reset_index(drop=True).to_csv(\"cutoff analysis/twenty variable importance all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233f2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047beaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55121fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
